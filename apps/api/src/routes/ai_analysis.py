# -*- coding: utf-8 -*-
"""
AIåˆ†æè·¯ç”±
æä¾›AIæ–‡æ¡£åˆ†æå’Œäº§å“ä¿¡æ¯æå–çš„APIç«¯ç‚¹
"""
import os
import logging
import time
import uuid
from flask import Blueprint, request, jsonify, current_app
from flask_jwt_extended import jwt_required, get_jwt_identity
from marshmallow import Schema, fields, ValidationError, validate

from src.models import db, Product, AIAnalysisRecord
from src.utils.decorators import require_role, require_auth, get_current_user
from src.services.ai_analyzer import AIAnalyzer
from src.middleware.performance_monitor import performance_monitor, monitor_performance
from src.middleware.ai_service_manager import ai_service_manager, RequestContext

logger = logging.getLogger(__name__)
ai_analysis_bp = Blueprint('ai_analysis', __name__)

# åˆå§‹åŒ–AIåˆ†æå™¨
ai_analyzer = AIAnalyzer()

def safe_string_conversion(value, default=''):
    """
    å®‰å…¨åœ°å°†ä»»æ„å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    
    Args:
        value: å¾…è½¬æ¢çš„å€¼
        default: è½¬æ¢å¤±è´¥æ—¶çš„é»˜è®¤å€¼
        
    Returns:
        str: è½¬æ¢åçš„å­—ç¬¦ä¸²
    """
    try:
        if value is None:
            return default
        if isinstance(value, str):
            return value
        if isinstance(value, (int, float, bool)):
            return str(value)
        # å¯¹äºå¤æ‚å¯¹è±¡ï¼Œå°è¯•è½¬æ¢ä½†é™åˆ¶é•¿åº¦
        str_value = str(value)
        return str_value if len(str_value) < 1000 else default
    except Exception:
        return default

def validate_and_transform_product_data(product_data):
    """
    éªŒè¯å’Œè½¬æ¢äº§å“æ•°æ®ï¼Œç¡®ä¿æ•°æ®ç»“æ„ä¸€è‡´æ€§ - å¢å¼ºç‰ˆæœ¬
    
    Args:
        product_data: ä»AIåˆ†ææˆ–å‰ç«¯æäº¤çš„äº§å“æ•°æ®
        
    Returns:
        dict: éªŒè¯å’Œæ ‡å‡†åŒ–åçš„äº§å“æ•°æ®
        
    Raises:
        ValueError: æ•°æ®éªŒè¯å¤±è´¥æ—¶æŠ›å‡º
    """
    try:
        # ğŸ” æ—¥å¿—è®°å½•åŸå§‹æ•°æ®ç»“æ„
        logger.info(f"ğŸ”§ å¼€å§‹éªŒè¯äº§å“æ•°æ®ï¼ŒåŸå§‹ç»“æ„: {list(product_data.keys()) if isinstance(product_data, dict) else type(product_data)}")
        
        # ğŸ›¡ï¸ å®¹é”™æ€§å¢å¼ºï¼šå¤„ç†Noneå’Œédictè¾“å…¥
        if product_data is None:
            logger.warning("âš ï¸ æ”¶åˆ°Noneäº§å“æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ç©ºç»“æ„")
            product_data = {}
        
        if not isinstance(product_data, dict):
            logger.error(f"âŒ äº§å“æ•°æ®ç±»å‹é”™è¯¯: æœŸæœ›dictï¼Œæ”¶åˆ°{type(product_data)}")
            raise ValueError(f"Expected dict, got {type(product_data)}. Received data: {repr(product_data)[:200]}")
        
        # âœ… éªŒè¯å’Œæ ‡å‡†åŒ–åŸºç¡€ä¿¡æ¯ - å¢å¼ºå®¹é”™æ€§
        basic_info = product_data.get('basic_info')
        
        # ğŸ›¡ï¸ å¤„ç†basic_infoä¸ºNoneæˆ–édictçš„æƒ…å†µ
        if basic_info is None:
            logger.warning("âš ï¸ basic_infoä¸ºNoneï¼Œåˆ›å»ºé»˜è®¤ç»“æ„")
            basic_info = {}
        elif not isinstance(basic_info, dict):
            logger.warning(f"âš ï¸ basic_infoç±»å‹é”™è¯¯: æœŸæœ›dictï¼Œæ”¶åˆ°{type(basic_info)}ï¼Œé‡ç½®ä¸ºç©ºdict")
            basic_info = {}
        
        # ğŸ”§ æ ‡å‡†åŒ–åŸºç¡€ä¿¡æ¯å­—æ®µ - å¢å¼ºå®‰å…¨å¤„ç†
        normalized_basic_info = {
            'name': safe_string_conversion(basic_info.get('name', ''), '').strip(),
            'code': safe_string_conversion(basic_info.get('code', ''), '').strip(), 
            'category': safe_string_conversion(basic_info.get('category', ''), '').strip(),
            'description': safe_string_conversion(basic_info.get('description', ''), '').strip(),
            'base_price': 0.0,
            'is_active': bool(basic_info.get('is_active', True)),
            'is_configurable': bool(basic_info.get('is_configurable', False))
        }
        
        # å®‰å…¨å¤„ç†ä»·æ ¼å­—æ®µ
        try:
            price_value = basic_info.get('base_price', 0)
            if isinstance(price_value, (int, float, str)):
                normalized_basic_info['base_price'] = float(str(price_value).replace(',', '')) if price_value else 0.0
        except (ValueError, TypeError) as e:
            logger.warning(f"âš ï¸ ä»·æ ¼å­—æ®µè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼0: {e}")
            normalized_basic_info['base_price'] = 0.0
        
        # ğŸ”§ æ™ºèƒ½å¿…å¡«å­—æ®µéªŒè¯ - æä¾›è‡ªåŠ¨ä¿®å¤å»ºè®®
        validation_errors = []
        auto_fixes = {}
        
        if not normalized_basic_info['name']:
            validation_errors.append("Product name is required")
            # ğŸ¤– å°è¯•ä»å…¶ä»–å­—æ®µæ¨æ–­äº§å“åç§°
            if product_data.get('summary') and 'product:' in product_data.get('summary', '').lower():
                # ä»æ‘˜è¦ä¸­æå–äº§å“åç§°
                import re
                match = re.search(r'product:\s*([^|]+)', product_data.get('summary', ''), re.IGNORECASE)
                if match:
                    auto_fixes['name'] = match.group(1).strip()
                    
        if not normalized_basic_info['code']:
            validation_errors.append("Product code is required")
            # ğŸ¤– å°è¯•ç”Ÿæˆäº§å“ä»£ç 
            if normalized_basic_info['name']:
                import hashlib, time
                name_hash = hashlib.md5(normalized_basic_info['name'].encode()).hexdigest()[:6]
                auto_fixes['code'] = f"AUTO_{name_hash}_{int(time.time() % 10000)}"
            else:
                auto_fixes['code'] = f"AUTO_{int(time.time())}"
                
        # ğŸ”§ åº”ç”¨è‡ªåŠ¨ä¿®å¤
        if auto_fixes:
            logger.info(f"ğŸ¤– åº”ç”¨è‡ªåŠ¨æ•°æ®ä¿®å¤: {auto_fixes}")
            normalized_basic_info.update(auto_fixes)
            # é‡æ–°éªŒè¯
            validation_errors = [err for err in validation_errors if not any(field in err.lower() for field in auto_fixes.keys())]
            
        # ğŸš¨ å¦‚æœä»æœ‰éªŒè¯é”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸
        if validation_errors:
            error_msg = "; ".join(validation_errors)
            logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {error_msg}")
            raise ValueError(f"Data validation failed: {error_msg}")
        
        # ğŸ”§ æ ‡å‡†åŒ–è§„æ ¼ä¿¡æ¯ - å¢å¼ºå®¹é”™å’Œè¿‡æ»¤
        specifications = product_data.get('specifications', {})
        normalized_specifications = {}
        
        # ğŸ›¡ï¸ ç¡®ä¿specificationsæ˜¯dictç±»å‹
        if not isinstance(specifications, dict):
            logger.warning(f"âš ï¸ specificationsç±»å‹é”™è¯¯: æœŸæœ›dictï¼Œæ”¶åˆ°{type(specifications)}ï¼Œé‡ç½®ä¸ºç©ºdict")
            specifications = {}
        
        # ğŸ§¹ æ— æ•ˆè§„æ ¼å‚æ•°è¿‡æ»¤æ¨¡å¼
        invalid_patterns = [
            r'^h$',  # å•ä¸ªå­—ç¬¦"h"
            r'^[a-z]$',  # å•ä¸ªå­—æ¯
            r'^\d+$',  # å•çº¯æ•°å­—
            r'hyperlink',  # åŒ…å«HYPERLINK
            r'^(EMBED|MERGEFORMAT|CERTIFICATE|PACKING|PAGE|TEST)$',  # Wordæ ¼å¼æ ‡è¯†
            r'^(Toc\d+|_Toc|_Ref)',  # æ–‡æ¡£ç»“æ„æ ‡è¯†
            r'^\d+\s+(HYPERLINK|PAGE|EMBED)',  # æ•°å­—+æ–‡æ¡£æ ¼å¼
            r'^[\s\-_=]+$'  # åªæœ‰æ ¼å¼å­—ç¬¦
        ]
        
        import re
        compiled_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in invalid_patterns]
        
        if isinstance(specifications, dict):
            for spec_key, spec_value in specifications.items():
                if not spec_key or not spec_key.strip():
                    continue
                    
                # ğŸ§¹ æ£€æŸ¥æ˜¯å¦ä¸ºæ— æ•ˆè§„æ ¼å‚æ•°
                key_str = spec_key.strip()
                value_str = safe_string_conversion(spec_value if not isinstance(spec_value, dict) else spec_value.get('value', ''), '')
                combined_text = f"{key_str} {value_str}"
                
                # è·³è¿‡æ˜æ˜¾æ— æ•ˆçš„å‚æ•°
                is_invalid = any(pattern.search(combined_text) for pattern in compiled_patterns)
                if is_invalid:
                    logger.debug(f"ğŸ§¹ è¿‡æ»¤æ— æ•ˆè§„æ ¼å‚æ•°: '{key_str}' = '{value_str}'")
                    continue
                
                # å¤„ç†ä¸åŒæ ¼å¼çš„è§„æ ¼å€¼
                if isinstance(spec_value, dict):
                    # å¦‚æœæ˜¯å¤æ‚å¯¹è±¡ï¼Œä¿æŒç»“æ„ä½†ç¡®ä¿å¿…è¦å­—æ®µ
                    normalized_spec = {
                        'value': safe_string_conversion(spec_value.get('value', ''), ''),
                        'unit': safe_string_conversion(spec_value.get('unit', ''), ''),
                        'description': safe_string_conversion(spec_value.get('description', ''), '')
                    }
                    # å¦‚æœæœ‰æ•°å€¼å­—æ®µï¼Œä¿ç•™å®ƒ
                    if 'numeric_value' in spec_value:
                        try:
                            normalized_spec['numeric_value'] = float(spec_value['numeric_value'])
                        except (ValueError, TypeError):
                            pass
                    normalized_specifications[key_str] = normalized_spec
                else:
                    # ç®€å•å€¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    normalized_specifications[key_str] = {
                        'value': safe_string_conversion(spec_value, ''),
                        'unit': '',
                        'description': ''
                    }
        
        # ğŸ”§ å¤„ç†å…¶ä»–å­—æ®µï¼Œç¡®ä¿å®‰å…¨æ€§å’Œç±»å‹æ­£ç¡®æ€§
        def safe_list_conversion(value, field_name):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºåˆ—è¡¨ç±»å‹"""
            if value is None:
                return []
            if isinstance(value, list):
                return value
            logger.warning(f"âš ï¸ {field_name}ç±»å‹é”™è¯¯: æœŸæœ›listï¼Œæ”¶åˆ°{type(value)}ï¼Œé‡ç½®ä¸ºç©ºlist")
            return []
            
        def safe_dict_conversion(value, field_name):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºå­—å…¸ç±»å‹"""
            if value is None:
                return {}
            if isinstance(value, dict):
                return value
            logger.warning(f"âš ï¸ {field_name}ç±»å‹é”™è¯¯: æœŸæœ›dictï¼Œæ”¶åˆ°{type(value)}ï¼Œé‡ç½®ä¸ºç©ºdict")
            return {}
        
        validated_data = {
            'basic_info': normalized_basic_info,
            'specifications': normalized_specifications,
            'configuration_schema': safe_dict_conversion(product_data.get('configuration_schema'), 'configuration_schema'),
            'detailed_description': safe_string_conversion(product_data.get('detailed_description', ''), ''),
            'features': safe_list_conversion(product_data.get('features'), 'features'),
            'application_scenarios': safe_list_conversion(product_data.get('application_scenarios'), 'application_scenarios'),
            'accessories': safe_list_conversion(product_data.get('accessories'), 'accessories'),
            'certificates': safe_list_conversion(product_data.get('certificates'), 'certificates'),
            'support_info': safe_dict_conversion(product_data.get('support_info'), 'support_info')
        }
        
        # ğŸ“Š æ—¥å¿—è®°å½•éªŒè¯ç»“æœ
        logger.info(f"âœ… æ•°æ®éªŒè¯æˆåŠŸ: {normalized_basic_info['name']} ({normalized_basic_info['code']})")
        logger.info(f"ğŸ“Š è§„æ ¼å‚æ•°æ•°é‡: {len(normalized_specifications)}")
        
        return validated_data
        
    except Exception as e:
        # ğŸ” å¢å¼ºé”™è¯¯å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯
        error_type = type(e).__name__
        error_msg = str(e)
        
        # ğŸ“Š ç”Ÿæˆè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
        debug_info = {
            'error_type': error_type,
            'error_message': error_msg,
            'data_type': type(product_data).__name__,
            'data_keys': list(product_data.keys()) if isinstance(product_data, dict) else 'N/A',
            'basic_info_present': 'basic_info' in product_data if isinstance(product_data, dict) else False,
            'basic_info_type': type(product_data.get('basic_info')).__name__ if isinstance(product_data, dict) else 'N/A'
        }
        
        logger.error(f"âŒ äº§å“æ•°æ®éªŒè¯å¤±è´¥ [{error_type}]: {error_msg}")
        logger.error(f"ğŸ” è°ƒè¯•ä¿¡æ¯: {debug_info}")
        
        # ğŸ”’ å®‰å…¨åœ°è®°å½•éƒ¨åˆ†æ•°æ®ç»“æ„ï¼ˆé¿å…æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
        if isinstance(product_data, dict):
            safe_sample = {k: f"<{type(v).__name__}>" for k, v in list(product_data.items())[:5]}
            logger.error(f"ğŸ“„ æ•°æ®ç»“æ„ç¤ºä¾‹ (å‰5ä¸ªå­—æ®µ): {safe_sample}")
        else:
            logger.error(f"ğŸ“„ æ•°æ®å†…å®¹: {repr(product_data)[:200]}...")
            
        # ğŸ¯ æä¾›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        if "name is required" in error_msg.lower() or "code is required" in error_msg.lower():
            user_friendly_msg = "äº§å“åŸºç¡€ä¿¡æ¯ä¸å®Œæ•´ï¼Œè¯·ç¡®ä¿åŒ…å«äº§å“åç§°å’Œäº§å“ä»£ç "
        elif "basic_info must be a dictionary" in error_msg:
            user_friendly_msg = "äº§å“åŸºç¡€ä¿¡æ¯æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›å­—å…¸æ ¼å¼"
        elif "Expected dict" in error_msg:
            user_friendly_msg = "äº§å“æ•°æ®æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›JSONå¯¹è±¡æ ¼å¼"
        else:
            user_friendly_msg = f"æ•°æ®éªŒè¯å¤±è´¥: {error_msg}"
            
        raise ValueError(user_friendly_msg)

# Schemas for request validation
class ProductCreateFromAISchema(Schema):
    """ä»AIåˆ†æç»“æœåˆ›å»ºäº§å“çš„è¯·æ±‚æ¨¡å¼"""
    analysis_id = fields.Int(required=True, validate=validate.Range(min=1))
    product_data = fields.Dict(required=True)
    user_modifications = fields.Dict(missing={})

@ai_analysis_bp.route('/supported-formats', methods=['GET'])
@jwt_required()
@require_auth
def get_supported_formats():
    """è·å–æ”¯æŒçš„æ–‡æ¡£æ ¼å¼ä¿¡æ¯"""
    try:
        formats_info = ai_analyzer.get_supported_formats()
        
        return jsonify({
            'success': True,
            'formats': formats_info
        })
        
    except Exception as e:
        logger.error(f"Error getting supported formats: {str(e)}")
        return jsonify({'error': 'Failed to get format information'}), 500

@ai_analysis_bp.route('/analyze-document', methods=['POST'])
@jwt_required()
@require_role('engineer', 'admin', 'manager')
@monitor_performance
def analyze_document():
    """åˆ†æäº§å“æ–‡æ¡£ï¼Œæå–äº§å“ä¿¡æ¯ - å¢å¼ºç‰ˆæœ¬"""
    request_id = str(uuid.uuid4())
    start_time = time.time()
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼ 
        if 'document' not in request.files:
            return jsonify({'error': 'No document file provided'}), 400
        
        file = request.files['document']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # è·å–å½“å‰ç”¨æˆ·
        current_user_id = get_jwt_identity()
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_size = len(file.read())
        file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        file_type = file.content_type or 'unknown'
        
        logger.info(f"ğŸš€ AIåˆ†æè¯·æ±‚ {request_id}: æ–‡ä»¶={file.filename}, å¤§å°={file_size}bytes, ç”¨æˆ·={current_user_id}")
        
        # ğŸ“Š æ£€æŸ¥æœåŠ¡çŠ¶æ€å’Œé˜Ÿåˆ—
        queue_status = ai_service_manager.get_queue_status()
        service_status = queue_status['service_status']
        
        if service_status == 'unavailable':
            logger.error(f"âŒ AIæœåŠ¡ä¸å¯ç”¨ï¼Œæ‹’ç»è¯·æ±‚ {request_id}")
            return jsonify({
                'success': False,
                'error': 'AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•',
                'service_status': service_status,
                'queue_info': {
                    'queue_size': queue_status['queue_size'],
                    'processing_count': queue_status['processing_count']
                }
            }), 503
        
        # ğŸ”§ åˆ›å»ºè¯·æ±‚ä¸Šä¸‹æ–‡
        context = RequestContext(
            request_id=request_id,
            user_id=current_user_id,
            priority=8 if file_size < 1024*1024 else 6,  # å°æ–‡ä»¶é«˜ä¼˜å…ˆçº§
            timeout=180.0,  # 3åˆ†é’Ÿè¶…æ—¶
            created_at=start_time,
            file_size=file_size,
            file_type=file_type
        )
        
        # å¦‚æœæœåŠ¡é™çº§ï¼Œæä¾›å¿«é€Ÿå“åº”é€‰é¡¹
        if service_status == 'degraded':
            logger.warning(f"âš ï¸ AIæœåŠ¡é™çº§æ¨¡å¼ï¼Œè¯·æ±‚ {request_id} å°†ä½¿ç”¨ç®€åŒ–å¤„ç†")
            # å¯ä»¥é€‰æ‹©ç›´æ¥å¤„ç†æˆ–æ’é˜Ÿ
            if queue_status['queue_size'] > 20:
                return jsonify({
                    'success': False,
                    'error': 'AIåˆ†ææœåŠ¡è´Ÿè½½è¾ƒé«˜ï¼Œå»ºè®®ç¨åé‡è¯•',
                    'service_status': service_status,
                    'estimated_wait_time': queue_status['queue_size'] * 30,  # ä¼°ç®—ç­‰å¾…æ—¶é—´
                    'recommendations': ai_service_manager.get_service_recommendations()
                }), 429
        
        # ğŸ¯ æäº¤åˆ°AIæœåŠ¡ç®¡ç†å™¨é˜Ÿåˆ—
        queued = ai_service_manager.submit_analysis_request(context)
        if not queued:
            logger.error(f"âŒ è¯·æ±‚ {request_id} æ— æ³•åŠ å…¥å¤„ç†é˜Ÿåˆ—")
            return jsonify({
                'success': False,
                'error': 'AIåˆ†æé˜Ÿåˆ—å·²æ»¡ï¼Œè¯·ç¨åé‡è¯•',
                'queue_info': queue_status,
                'recommendations': ai_service_manager.get_service_recommendations()
            }), 429
        
        # âš¡ ç›´æ¥å¤„ç†ï¼ˆåœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥æ˜¯å¼‚æ­¥å¤„ç†ï¼‰
        # ä¸ºäº†ä¿æŒAPIå…¼å®¹æ€§ï¼Œæˆ‘ä»¬ä»ç„¶åŒæ­¥å¤„ç†
        logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†AIåˆ†æè¯·æ±‚ {request_id}")
        
        # ä½¿ç”¨AIåˆ†æå™¨å¤„ç†æ–‡æ¡£ï¼ˆåŒ…å«ç”¨æˆ·IDä»¥è·å¾—ä¸ªæ€§åŒ–åˆ†æï¼‰
        analysis_result = ai_analyzer.analyze_product_document(file, user_id=current_user_id)
        
        # ğŸ“ ä¿å­˜åˆ†æè®°å½•åˆ°æ•°æ®åº“
        analysis_record = AIAnalysisRecord.create_from_analysis(
            analysis_result,
            user_id=current_user_id
        )
        analysis_record.save()
        
        # âœ… éªŒè¯åˆ†æç»“æœ
        validation = ai_analyzer.validate_analysis_result(analysis_result)
        
        # ğŸ“‹ ç”Ÿæˆåˆ†ææ‘˜è¦
        summary = ai_analyzer.generate_analysis_summary(analysis_result)
        
        # ğŸ“Š è®°å½•æ€§èƒ½æŒ‡æ ‡
        processing_time = time.time() - start_time
        performance_monitor.record_request(
            endpoint='/ai-analysis/analyze-document',
            method='POST',
            duration=processing_time,
            status_code=200 if analysis_result.get('success') else 400
        )
        
        # ğŸ“¤ æ„å»ºå“åº”
        response_data = {
            'success': analysis_result.get('success', False),
            'request_id': request_id,
            'analysis_id': analysis_record.id,
            'document_info': analysis_result.get('document_info', {}),
            'extracted_data': analysis_result.get('extracted_data', {}),
            'confidence_scores': analysis_result.get('confidence_scores', {}),
            'personalized_hints': analysis_result.get('personalized_hints', []),
            'predicted_modifications': analysis_result.get('predicted_modifications', {}),
            'validation': validation,
            'summary': summary,
            'text_preview': analysis_result.get('text_preview', ''),
            'analysis_timestamp': analysis_result.get('analysis_timestamp'),
            'processing_time': round(processing_time, 2),
            'service_status': service_status,
            'queue_info': {
                'queue_size': ai_service_manager.get_queue_status()['queue_size'],
                'processing_count': len(ai_service_manager.get_processing_requests())
            }
        }
        
        if not analysis_result.get('success'):
            response_data['error'] = analysis_result.get('error')
            logger.warning(f"âš ï¸ AIåˆ†æå¤±è´¥ {request_id}: {analysis_result.get('error')}")
            return jsonify(response_data), 400
        
        logger.info(f"âœ… AIåˆ†ææˆåŠŸå®Œæˆ {request_id}: è®°å½•ID={analysis_record.id}, è€—æ—¶={processing_time:.2f}s")
        return jsonify(response_data), 200
        
    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = str(e)
        
        # ğŸ“Š è®°å½•é”™è¯¯æŒ‡æ ‡
        performance_monitor.record_request(
            endpoint='/ai-analysis/analyze-document',
            method='POST',
            duration=processing_time,
            status_code=500,
            error_msg=error_msg
        )
        
        logger.error(f"ğŸ’¥ AIåˆ†æå¼‚å¸¸ {request_id}: {error_msg}, è€—æ—¶={processing_time:.2f}s")
        
        return jsonify({
            'success': False,
            'request_id': request_id,
            'error': f'AIåˆ†æå¤±è´¥: {error_msg}',
            'processing_time': round(processing_time, 2),
            'service_status': ai_service_manager.get_queue_status()['service_status']
        }), 500

@ai_analysis_bp.route('/analysis/<int:analysis_id>', methods=['GET'])
@jwt_required()
@require_auth
def get_analysis_result(analysis_id):
    """è·å–æŒ‡å®šåˆ†æè®°å½•çš„ç»“æœ"""
    try:
        analysis_record = AIAnalysisRecord.query.get_or_404(analysis_id)
        
        return jsonify({
            'success': True,
            'analysis': analysis_record.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Error getting analysis result {analysis_id}: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/debug/<int:analysis_id>', methods=['GET'])
def debug_analysis_data(analysis_id):
    """ğŸ”§ è°ƒè¯•ç«¯ç‚¹ - æ£€æŸ¥AIåˆ†æç»“æœçš„åŸå§‹æ•°æ®ç»“æ„"""
    try:
        analysis_record = AIAnalysisRecord.query.get_or_404(analysis_id)
        extracted_data = analysis_record.get_extracted_data()
        confidence_scores = analysis_record.get_confidence_scores()
        
        # è¯¦ç»†çš„æ•°æ®ç»“æ„æ£€æŸ¥
        debug_info = {
            'analysis_id': analysis_id,
            'record_found': True,
            'document_name': analysis_record.document_name,
            'analysis_summary': analysis_record.analysis_summary,
            'success': analysis_record.success,
            'has_extracted_data': bool(extracted_data),
            'extracted_data_type': type(extracted_data).__name__,
            'extracted_data_keys': list(extracted_data.keys()) if isinstance(extracted_data, dict) else 'Not a dict',
            'basic_info_debug': {},
            'confidence_info': confidence_scores,
            'raw_extracted_data': extracted_data
        }
        
        # è¯¦ç»†æ£€æŸ¥basic_info
        if isinstance(extracted_data, dict) and 'basic_info' in extracted_data:
            basic_info = extracted_data['basic_info']
            debug_info['basic_info_debug'] = {
                'type': type(basic_info).__name__,
                'keys': list(basic_info.keys()) if isinstance(basic_info, dict) else 'Not a dict',
                'name_value': repr(basic_info.get('name', 'KEY_MISSING')) if isinstance(basic_info, dict) else 'N/A',
                'code_value': repr(basic_info.get('code', 'KEY_MISSING')) if isinstance(basic_info, dict) else 'N/A',
                'category_value': repr(basic_info.get('category', 'KEY_MISSING')) if isinstance(basic_info, dict) else 'N/A',
                'description_value': repr(basic_info.get('description', 'KEY_MISSING'))[:100] + '...' if isinstance(basic_info, dict) else 'N/A',
                'full_basic_info': basic_info if isinstance(basic_info, dict) else str(basic_info)
            }
        
        logger.info(f"ğŸ”§ è°ƒè¯•åˆ†æID {analysis_id}: {debug_info}")
        return jsonify(debug_info)
        
    except Exception as e:
        logger.error(f"è°ƒè¯•ç«¯ç‚¹é”™è¯¯: {str(e)}")
        return jsonify({'error': str(e), 'analysis_id': analysis_id}), 500

@ai_analysis_bp.route('/analysis/<int:analysis_id>', methods=['PUT'])
@jwt_required()
@require_role('engineer', 'admin', 'manager')
def update_analysis_modifications(analysis_id):
    """æ›´æ–°åˆ†æè®°å½•çš„ç”¨æˆ·ä¿®æ­£ä¿¡æ¯"""
    try:
        analysis_record = AIAnalysisRecord.query.get_or_404(analysis_id)
        
        request_data = request.get_json()
        if not request_data:
            return jsonify({'error': 'No data provided'}), 400
        
        # æ›´æ–°ç”¨æˆ·ä¿®æ­£è®°å½•
        if 'user_modifications' in request_data:
            analysis_record.set_user_modifications(request_data['user_modifications'])
        
        if 'final_data' in request_data:
            analysis_record.set_final_data(request_data['final_data'])
        
        analysis_record.save()
        
        return jsonify({
            'success': True,
            'message': 'Analysis modifications updated successfully',
            'analysis': analysis_record.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Error updating analysis modifications {analysis_id}: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/validate-data/<int:analysis_id>', methods=['GET'])
@jwt_required()
@require_auth
def validate_analysis_data(analysis_id):
    """
    éªŒè¯åˆ†ææ•°æ®çš„ä¸€è‡´æ€§å’Œå®Œæ•´æ€§
    """
    try:
        # è·å–åˆ†æè®°å½•
        analysis_record = AIAnalysisRecord.query.get_or_404(analysis_id)
        extracted_data = analysis_record.get_extracted_data()
        
        # æ‰§è¡Œæ•°æ®éªŒè¯
        validation_result = {
            'analysis_id': analysis_id,
            'validation_passed': False,
            'issues': [],
            'warnings': [],
            'data_structure': {},
            'suggestions': []
        }
        
        try:
            # å°è¯•éªŒè¯æ•°æ®ç»“æ„
            validated_data = validate_and_transform_product_data(extracted_data)
            validation_result['validation_passed'] = True
            validation_result['data_structure'] = {
                'basic_info_fields': list(validated_data['basic_info'].keys()),
                'specifications_count': len(validated_data['specifications']),
                'features_count': len(validated_data['features']),
                'has_extended_data': bool(validated_data.get('detailed_description'))
            }
            
        except ValueError as e:
            validation_result['issues'].append(str(e))
            validation_result['suggestions'].append('è¯·æ£€æŸ¥AIåˆ†æç»“æœçš„æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®')
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if not extracted_data.get('basic_info', {}).get('name'):
            validation_result['warnings'].append('äº§å“åç§°ç¼ºå¤±')
        if not extracted_data.get('basic_info', {}).get('code'):
            validation_result['warnings'].append('äº§å“ç¼–ç ç¼ºå¤±')
        if not extracted_data.get('specifications'):
            validation_result['warnings'].append('æŠ€æœ¯è§„æ ¼å‚æ•°ç¼ºå¤±')
            
        return jsonify(validation_result)
        
    except Exception as e:
        logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
        return jsonify({'error': f'Validation failed: {str(e)}'}), 500

@ai_analysis_bp.route('/create-product', methods=['POST'])
@jwt_required()
@require_role('engineer', 'admin', 'manager')
def create_product_from_analysis():
    """åŸºäºAIåˆ†æç»“æœåˆ›å»ºäº§å“"""
    try:
        # éªŒè¯è¯·æ±‚æ•°æ®
        schema = ProductCreateFromAISchema()
        request_data = schema.load(request.get_json())
        
        analysis_id = request_data['analysis_id']
        product_data = request_data['product_data']
        user_modifications = request_data['user_modifications']
        
        # è·å–åˆ†æè®°å½•
        analysis_record = AIAnalysisRecord.query.get_or_404(analysis_id)
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åˆ›å»ºè¿‡äº§å“
        if analysis_record.created_product_id:
            return jsonify({
                'error': 'Product has already been created from this analysis',
                'existing_product_id': analysis_record.created_product_id
            }), 400
        
        # ğŸ”§ æ•°æ®éªŒè¯å’Œè½¬æ¢å±‚
        try:
            validated_data = validate_and_transform_product_data(product_data)
            logger.info(f"âœ… äº§å“æ•°æ®éªŒè¯é€šè¿‡: {validated_data.get('basic_info', {}).get('name', 'Unknown')}")
        except ValueError as e:
            logger.error(f"âŒ äº§å“æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
            return jsonify({'error': f'Data validation failed: {str(e)}'}), 400
        
        # éªŒè¯å¹¶å¤„ç†äº§å“ä»£ç é‡å¤é—®é¢˜
        product_code = validated_data.get('basic_info', {}).get('code', '')
        if Product.query.filter_by(code=product_code).first():
            # ç”Ÿæˆå”¯ä¸€çš„äº§å“ä»£ç 
            import time
            import hashlib
            timestamp = str(int(time.time()))
            original_code = product_code
            
            # å°è¯•ä¸åŒçš„å”¯ä¸€åŒ–ç­–ç•¥
            for i in range(1, 100):  # æœ€å¤šå°è¯•99æ¬¡
                if i == 1:
                    # ç¬¬ä¸€æ¬¡å°è¯•ï¼šæ·»åŠ æ—¶é—´æˆ³åç¼€
                    new_code = f"{original_code}_{timestamp[-4:]}"
                elif i <= 10:
                    # 2-10æ¬¡ï¼šæ·»åŠ é€’å¢æ•°å­—
                    new_code = f"{original_code}_{i:02d}"
                else:
                    # 11+æ¬¡ï¼šä½¿ç”¨å“ˆå¸Œå€¼ç¡®ä¿å”¯ä¸€æ€§
                    hash_input = f"{original_code}_{timestamp}_{i}"
                    hash_suffix = hashlib.md5(hash_input.encode()).hexdigest()[:6]
                    new_code = f"{original_code}_{hash_suffix}"
                
                if not Product.query.filter_by(code=new_code).first():
                    logger.info(f"ğŸ”§ äº§å“ä»£ç å†²çªå·²è§£å†³: '{original_code}' â†’ '{new_code}'")
                    validated_data['basic_info']['code'] = new_code
                    product_code = new_code
                    break
            else:
                # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯
                logger.error(f"âŒ æ— æ³•ç”Ÿæˆå”¯ä¸€çš„äº§å“ä»£ç ï¼ŒåŸå§‹ä»£ç : {original_code}")
                return jsonify({
                    'error': f'Unable to generate unique product code. Original code "{original_code}" conflicts with existing products.'
                }), 400
        
        # åˆ›å»ºäº§å“
        product = Product()
        
        # è®¾ç½®åŸºç¡€ä¿¡æ¯ - ä½¿ç”¨éªŒè¯åçš„æ•°æ®
        basic_info = validated_data.get('basic_info', {})
        product.name = basic_info.get('name', '')
        product.code = basic_info.get('code', '')
        product.description = basic_info.get('description', '')
        product.category = basic_info.get('category', '')
        product.base_price = basic_info.get('base_price', 0)
        product.is_active = basic_info.get('is_active', True)
        product.is_configurable = basic_info.get('is_configurable', False)
        
        # è®¾ç½®è§„æ ¼ä¿¡æ¯ - ä½¿ç”¨æ ‡å‡†åŒ–åçš„æ ¼å¼
        specifications = validated_data.get('specifications', {})
        if specifications:
            product.set_specifications(specifications)
        
        # è®¾ç½®é…ç½®æ¶æ„
        configuration_schema = validated_data.get('configuration_schema', {})
        if configuration_schema:
            product.set_configuration_schema(configuration_schema)
        
        # è®¾ç½®æ‰©å±•ä¿¡æ¯ - ä½¿ç”¨éªŒè¯åçš„æ•°æ®å’Œæ–°çš„æ¨¡å‹æ–¹æ³•
        if validated_data.get('detailed_description'):
            product.detailed_description = validated_data['detailed_description']
        if validated_data.get('application_scenarios'):
            product.set_application_scenarios(validated_data['application_scenarios'])
        if validated_data.get('features'):
            product.set_features(validated_data['features'])
        if validated_data.get('accessories'):
            product.set_accessories(validated_data['accessories'])
        if validated_data.get('certificates'):
            product.set_certificates(validated_data['certificates'])
        if validated_data.get('support_info'):
            product.set_support_info(validated_data['support_info'])
        
        # ä¿å­˜äº§å“
        product.save()
        
        # æ›´æ–°åˆ†æè®°å½• - ä½¿ç”¨éªŒè¯åçš„æ•°æ®
        analysis_record.created_product_id = product.id
        analysis_record.set_user_modifications(user_modifications)
        analysis_record.set_final_data(validated_data)  # ä¿å­˜éªŒè¯åçš„æ•°æ®
        analysis_record.save()
        
        # ğŸ“Š è®°å½•æ•°æ®è½¬æ¢æ—¥å¿—
        logger.info(f"âœ… äº§å“åˆ›å»ºæˆåŠŸ: ID={product.id}, Name={product.name}, Code={product.code}")
        logger.info(f"ğŸ“Š æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ - åŸå§‹å­—æ®µæ•°: {len(product_data.keys())}, éªŒè¯åå­—æ®µæ•°: {len(validated_data.keys())}")
        
        # è§¦å‘å­¦ä¹ æœºåˆ¶ï¼ˆå¦‚æœæœ‰ç”¨æˆ·ä¿®æ­£ï¼‰
        if user_modifications:
            try:
                learning_result = ai_analyzer.learn_from_user_modifications(
                    analysis_record_id=analysis_id,
                    original_data=analysis_record.get_extracted_data(),
                    final_data=product_data,
                    user_modifications=user_modifications
                )
                logger.info(f"Learning completed for analysis {analysis_id}: "
                           f"{learning_result.get('patterns_identified', 0)} patterns identified")
            except Exception as e:
                logger.error(f"Learning failed for analysis {analysis_id}: {str(e)}")
                # å­¦ä¹ å¤±è´¥ä¸å½±å“äº§å“åˆ›å»ºï¼Œåªè®°å½•é”™è¯¯
        
        logger.info(f"Product created successfully from AI analysis {analysis_id}: {product.id}")
        
        return jsonify({
            'success': True,
            'message': 'Product created successfully from AI analysis',
            'product': product.to_dict(),
            'product_id': product.id,
            'product_detail_url': f'/products/{product.id}',
            'analysis_id': analysis_id
        }), 201
        
    except ValidationError as err:
        return jsonify({'error': 'Validation error', 'details': err.messages}), 400
    except Exception as e:
        logger.error(f"Error creating product from AI analysis: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/history', methods=['GET'])
@jwt_required()
@require_auth
def get_analysis_history():
    """è·å–AIåˆ†æå†å²è®°å½•"""
    try:
        current_user_id = get_jwt_identity()
        
        # æŸ¥è¯¢å‚æ•°
        page = int(request.args.get('page', 1))
        per_page = min(int(request.args.get('per_page', 10)), 50)
        status = request.args.get('status')  # completed, failed
        
        # æ„å»ºæŸ¥è¯¢
        query = AIAnalysisRecord.query
        
        # ç”¨æˆ·è¿‡æ»¤ï¼ˆæ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„è®°å½•ï¼‰
        current_user = get_current_user()
        if current_user and current_user.role not in ['admin', 'manager']:
            query = query.filter_by(user_id=current_user_id)
        
        # çŠ¶æ€è¿‡æ»¤
        if status:
            query = query.filter_by(status=status)
        
        # åˆ†é¡µ
        records = query.order_by(AIAnalysisRecord.created_at.desc())\
                      .paginate(page=page, per_page=per_page, error_out=False)
        
        return jsonify({
            'success': True,
            'records': [record.to_dict() for record in records.items],
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': records.total,
                'pages': records.pages
            }
        })
        
    except Exception as e:
        logger.error(f"Error getting analysis history: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/statistics', methods=['GET'])
@jwt_required()
@require_role('admin', 'manager')
def get_analysis_statistics():
    """è·å–AIåˆ†æç»Ÿè®¡ä¿¡æ¯"""
    try:
        days = int(request.args.get('days', 30))
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        success_rate = AIAnalysisRecord.get_success_rate(days)
        avg_confidence = AIAnalysisRecord.get_average_confidence(days)
        
        # è·å–æ€»è®°å½•æ•°
        total_records = AIAnalysisRecord.query.count()
        successful_records = AIAnalysisRecord.query.filter_by(success=True).count()
        
        # è·å–æœ€è¿‘çš„åˆ†æè®°å½•
        recent_records = AIAnalysisRecord.query\
                                        .order_by(AIAnalysisRecord.created_at.desc())\
                                        .limit(5).all()
        
        return jsonify({
            'success': True,
            'statistics': {
                'total_analyses': total_records,
                'successful_analyses': successful_records,
                'success_rate': success_rate,
                'average_confidence': avg_confidence,
                'period_days': days
            },
            'recent_analyses': [record.to_dict() for record in recent_records]
        })
        
    except Exception as e:
        logger.error(f"Error getting analysis statistics: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/analysis/<int:analysis_id>', methods=['DELETE'])
@jwt_required()
@require_role('admin', 'manager')
def delete_analysis_record(analysis_id):
    """åˆ é™¤åˆ†æè®°å½•"""
    try:
        analysis_record = AIAnalysisRecord.query.get_or_404(analysis_id)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…³è”çš„äº§å“
        if analysis_record.created_product_id:
            return jsonify({
                'error': 'Cannot delete analysis record that has created a product'
            }), 400
        
        analysis_record.delete()
        
        return jsonify({
            'success': True,
            'message': 'Analysis record deleted successfully'
        })
        
    except Exception as e:
        logger.error(f"Error deleting analysis record {analysis_id}: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/learning/statistics', methods=['GET'])
@jwt_required()
@require_role('admin', 'manager')
def get_learning_statistics():
    """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
    try:
        days = int(request.args.get('days', 30))
        
        # è·å–å­¦ä¹ ç»Ÿè®¡
        stats = ai_analyzer.get_learning_statistics(days=days)
        
        return jsonify({
            'success': True,
            'statistics': stats,
            'period_days': days
        })
        
    except Exception as e:
        logger.error(f"Error getting learning statistics: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/learning/hints/<int:user_id>', methods=['POST'])
@jwt_required()
@require_auth
def get_personalized_hints(user_id):
    """è·å–ç”¨æˆ·ä¸ªæ€§åŒ–æç¤º"""
    try:
        # éªŒè¯æƒé™ï¼ˆç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„æç¤ºï¼Œç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ï¼‰
        current_user_id = get_jwt_identity()
        current_user = get_current_user()
        
        if current_user.role not in ['admin', 'manager'] and current_user_id != user_id:
            return jsonify({'error': 'Unauthorized access to user hints'}), 403
        
        request_data = request.get_json() or {}
        document_type = request_data.get('document_type', 'unknown')
        extracted_data = request_data.get('extracted_data', {})
        
        # è·å–ä¸ªæ€§åŒ–æç¤º
        hints = ai_analyzer.get_personalized_analysis_hints(
            user_id=user_id,
            document_type=document_type,
            extracted_data=extracted_data
        )
        
        return jsonify({
            'success': True,
            'hints': hints
        })
        
    except Exception as e:
        logger.error(f"Error getting personalized hints: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/learning/feedback', methods=['POST'])
@jwt_required()
@require_auth
def submit_learning_feedback():
    """æäº¤å­¦ä¹ åé¦ˆ"""
    try:
        from src.models.learning_pattern import LearningFeedback
        
        current_user_id = get_jwt_identity()
        request_data = request.get_json()
        
        # éªŒè¯è¯·æ±‚æ•°æ®
        required_fields = ['analysis_record_id', 'field_path', 'user_rating']
        for field in required_fields:
            if field not in request_data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        # åˆ›å»ºåé¦ˆè®°å½•
        feedback = LearningFeedback()
        feedback.analysis_record_id = request_data['analysis_record_id']
        feedback.user_id = current_user_id
        feedback.field_path = request_data['field_path']
        feedback.original_confidence = request_data.get('original_confidence')
        feedback.user_rating = request_data['user_rating']
        feedback.is_accurate = request_data.get('is_accurate', True)
        feedback.improvement_suggestion = request_data.get('improvement_suggestion', '')
        feedback.feedback_type = request_data.get('feedback_type', 'accuracy')
        
        feedback.save()
        
        return jsonify({
            'success': True,
            'message': 'Feedback submitted successfully',
            'feedback_id': feedback.id
        })
        
    except Exception as e:
        logger.error(f"Error submitting learning feedback: {str(e)}")
        return jsonify({'error': str(e)}), 500

@ai_analysis_bp.route('/learning/optimization/<document_type>', methods=['GET'])
@jwt_required()
@require_role('engineer', 'admin', 'manager')
def get_analysis_optimization(document_type):
    """è·å–æ–‡æ¡£ç±»å‹çš„åˆ†æä¼˜åŒ–é…ç½®"""
    try:
        category = request.args.get('category')
        
        # è·å–ä¼˜åŒ–é…ç½®
        optimization = ai_analyzer.optimize_analysis_for_document_type(
            document_type=document_type,
            category=category
        )
        
        return jsonify({
            'success': True,
            'optimization': optimization,
            'document_type': document_type,
            'category': category
        })
        
    except Exception as e:
        logger.error(f"Error getting analysis optimization: {str(e)}")
        return jsonify({'error': str(e)}), 500