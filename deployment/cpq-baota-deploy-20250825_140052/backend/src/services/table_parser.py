# -*- coding: utf-8 -*-
"""
å¤æ‚è¡¨æ ¼è§£ææœåŠ¡
ä¸“é—¨å¤„ç†å„ç§æ ¼å¼çš„è§„æ ¼è¡¨ã€å‚æ•°è¡¨ç­‰ç»“æ„åŒ–æ•°æ®
"""
import re
import logging
from typing import Dict, List, Any, Tuple, Optional
import pandas as pd
from io import StringIO

logger = logging.getLogger(__name__)

class TableParser:
    """å¤æ‚è¡¨æ ¼è§£æå™¨"""
    
    def __init__(self):
        # è¡¨æ ¼è¯†åˆ«æ¨¡å¼
        self.table_patterns = {
            'pipe_table': r'\|.*\|',  # |column1|column2|
            'tab_table': r'.*\t.*\t.*',  # tabåˆ†éš”
            'colon_table': r'.*:\s*.*',  # é”®å€¼å¯¹ key: value
            'dash_table': r'[-\s]*[-]+[-\s]*',  # åˆ†éš”çº¿
            'spec_table': r'^\s*[^\s]+\s+[^\s]+.*$',  # è§„æ ¼è¡¨æ ¼å¼
        }
        
        # ğŸš« æ— æ•ˆè§„æ ¼å‚æ•°è¿‡æ»¤æ¨¡å¼
        self.invalid_spec_patterns = {
            # Wordæ–‡æ¡£å†…éƒ¨æ ¼å¼ - å¢å¼ºHYPERLINKè¿‡æ»¤
            'word_format': [
                r'^(EMBED|MERGEFORMAT|HYPERLINK|CERTIFICATE|PACKING|PAGE|TEST)$',
                r'^(PBrush|Word\.Picture|OF CONFORMITY|LIST DATE|WIRES|RS232).*',
                r'.*EMBED.*',
                r'.*\.Picture\.',
                r'.*HYPERLINK.*',
                r'^.*HYPERLINK.*$',  # æ›´ä¸¥æ ¼çš„HYPERLINKè¿‡æ»¤
                r'^\d+\s+HYPERLINK.*',  # è¿‡æ»¤ "38 HYPERLINK" æ ¼å¼
                r'^[0-9]+\s*HYPERLINK.*'  # è¿‡æ»¤æ•°å­—+HYPERLINKç»„åˆ
            ],
            # æ–‡æ¡£ç»“æ„æ ‡è¯† - å¢å¼ºå•å­—ç¬¦è¿‡æ»¤
            'doc_structure': [
                r'^(Toc\d+|h|_Toc|_Ref).*',
                r'^[a-zA-Z]{1,3}\d+$',  # å¦‚ h, PAGEç­‰
                r'^\d+PAGE.*',
                r'.*Toc\d+.*',
                r'^h$',  # ä¸¥æ ¼è¿‡æ»¤å•ä¸ªå­—ç¬¦"h"
                r'^[a-z]$',  # è¿‡æ»¤æ‰€æœ‰å•ä¸ªå°å†™å­—æ¯
                r'^[A-Z]$',  # è¿‡æ»¤æ‰€æœ‰å•ä¸ªå¤§å†™å­—æ¯
                r'^\d+$'  # è¿‡æ»¤å•çº¯çš„æ•°å­—
            ],
            # éæŠ€æœ¯å‚æ•°
            'non_technical': [
                r'^(ç›®å½•|ç´¢å¼•|é¡µç |ç« èŠ‚|æ ‡é¢˜).*',
                r'^(CONTENTS|INDEX|PAGE|CHAPTER|TITLE).*',
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ç« èŠ‚é¡µ].*'
            ],
            # æ ¼å¼åŒ–å­—ç¬¦å’Œæ§åˆ¶å­—ç¬¦
            'format_chars': [
                r'^[\s\-_=]+$',  # åªæœ‰æ ¼å¼å­—ç¬¦
                r'^[^\w\u4e00-\u9fff]+$',  # åªæœ‰éæ–‡å­—å­—ç¬¦
                r'.*[\x00-\x1f\x7f-\x9f].*'  # æ§åˆ¶å­—ç¬¦
            ]
        }
        
        # âœ… æœ‰æ•ˆæŠ€æœ¯è§„æ ¼æ ‡è¯†æ¨¡å¼ - é’ˆå¯¹OCRä¼˜åŒ–
        self.valid_spec_patterns = [
            # ä¸­æ–‡æŠ€æœ¯å‚æ•° - æ‰©å±•å…³é”®è¯
            r'(ç”µå‹|ç”µæµ|åŠŸç‡|é¢‘ç‡|æ¸©åº¦|æ¹¿åº¦|ç²¾åº¦|èŒƒå›´|å®¹é‡|é€Ÿåº¦|æ—¶é—´|å‹åŠ›|æµé‡|é˜»æŠ—|ç›¸æ•°|è¾“å‡º|è¾“å…¥)',
            r'(å·¥ä½œ|é¢å®š|æœ€å¤§|æœ€å°|æ ‡å‡†|æµ‹é‡|æµ‹è¯•|æ£€æµ‹|ä¿æŠ¤|æ§åˆ¶|æ˜¾ç¤º|é€šä¿¡|æ¥å£|å°ºå¯¸|é‡é‡)',
            r'(ç»§ç”µ|ä¿æŠ¤|è£…ç½®|è®¾å¤‡|ä»ªå™¨|ä»ªè¡¨|æ¨¡å—|å•å…ƒ|ç³»ç»Ÿ|å›è·¯|ç”µè·¯)',
            # è‹±æ–‡æŠ€æœ¯å‚æ•° - æ‰©å±•å…³é”®è¯
            r'(voltage|current|power|frequency|temperature|humidity|accuracy|range|capacity)',
            r'(speed|time|pressure|flow|impedance|phase|output|input|working|rated|max|min)',
            r'(relay|protection|device|equipment|instrument|module|unit|system|circuit)',
            # å•ä½æ¨¡å¼ - æ‰©å±•å•ä½è¯†åˆ«
            r'.*[VvAaWwHhÎ©â„ƒâ„‰%mMkKgGÎ©]+.*',
            r'.*[0-9]+\s*[VvAaWwHhÎ©â„ƒâ„‰%mMkKgG].*',  # æ•°å­—+å•ä½
            # æ•°å€¼æ¨¡å¼ - æ›´å®½æ¾çš„æ•°å€¼è¯†åˆ«
            r'.*\d+.*',
            r'.*[0-9]+[\.,][0-9]+.*',  # å°æ•°
            r'.*[0-9]+\s*[-~Â±]\s*[0-9]+.*',  # èŒƒå›´å€¼
            # OCRå¸¸è§çš„æŠ€æœ¯è¯æ±‡ï¼ˆå¯èƒ½æœ‰è¯†åˆ«é”™è¯¯ï¼‰
            r'.*(æµ‹è¯•|æ£€æµ‹|ä¿æŠ¤|ç»§ç”µ|è£…ç½®|è®¾å¤‡|æ€§èƒ½|å‚æ•°|è§„æ ¼|æŒ‡æ ‡).*',
            r'.*(test|protect|relay|device|spec|param|performance).*'
        ]
        
        # å¸¸è§è¡¨å¤´è¯†åˆ«
        self.header_patterns = {
            'zh': {
                'parameter': r'(å‚æ•°|è§„æ ¼|æŒ‡æ ‡|é¡¹ç›®|åç§°)',
                'value': r'(å€¼|æ•°å€¼|å‚æ•°å€¼|è§„æ ¼å€¼)',
                'unit': r'(å•ä½|é‡çº²)',
                'description': r'(è¯´æ˜|æè¿°|å¤‡æ³¨|æ³¨é‡Š)',
                'range': r'(èŒƒå›´|åŒºé—´|é™å€¼)',
                'condition': r'(æ¡ä»¶|ç¯å¢ƒ|çŠ¶æ€)'
            },
            'en': {
                'parameter': r'(parameter|specification|spec|item|name)',
                'value': r'(value|val|data)',
                'unit': r'(unit|dimension)',
                'description': r'(description|desc|note|remark)',
                'range': r'(range|limit)',
                'condition': r'(condition|environment|state)'
            }
        }
        
        # æ•°å€¼å’Œå•ä½è¯†åˆ«æ¨¡å¼
        self.value_patterns = {
            'number_with_unit': r'([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\s*([a-zA-ZÂ°â„ƒâ„‰%Î©]+)',
            'range_value': r'([-+]?\d*\.?\d+)\s*[-~]\s*([-+]?\d*\.?\d+)',
            'tolerance': r'([-+]?\d*\.?\d+)\s*[Â±]\s*([-+]?\d*\.?\d+)',
            'percentage': r'([-+]?\d*\.?\d+)\s*%',
            'scientific': r'([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)',
        }
    
    def parse_document_tables(self, text_content: str) -> Dict[str, Any]:
        """
        ä»æ–‡æ¡£ä¸­è§£ææ‰€æœ‰è¡¨æ ¼
        
        Args:
            text_content: æ–‡æ¡£æ–‡æœ¬å†…å®¹
            
        Returns:
            Dict: è§£æç»“æœ
        """
        try:
            # æŒ‰è¡Œåˆ†å‰²æ–‡æœ¬
            lines = text_content.split('\n')
            
            # è¯†åˆ«è¡¨æ ¼åŒºåŸŸ
            table_regions = self._identify_table_regions(lines)
            
            # è§£ææ¯ä¸ªè¡¨æ ¼åŒºåŸŸ
            parsed_tables = []
            for region in table_regions:
                table_data = self._parse_table_region(region)
                if table_data:
                    parsed_tables.append(table_data)
            
            # æå–è§„æ ¼ä¿¡æ¯
            specifications = self._extract_specifications(parsed_tables, text_content)
            
            # æå–æ€§èƒ½å‚æ•°
            performance_params = self._extract_performance_params(parsed_tables, text_content)
            
            result = {
                'tables_found': len(parsed_tables),
                'specifications': specifications,
                'performance_parameters': performance_params,
                'raw_tables': parsed_tables,
                'parsing_confidence': self._calculate_parsing_confidence(parsed_tables)
            }
            
            logger.info(f"Parsed {len(parsed_tables)} tables with {len(specifications)} specifications")
            return result
            
        except Exception as e:
            logger.error(f"Table parsing failed: {str(e)}")
            return {
                'tables_found': 0,
                'specifications': {},
                'performance_parameters': {},
                'raw_tables': [],
                'parsing_confidence': 0.0,
                'error': str(e)
            }
    
    def _identify_table_regions(self, lines: List[str]) -> List[Dict[str, Any]]:
        """è¯†åˆ«æ–‡æœ¬ä¸­çš„è¡¨æ ¼åŒºåŸŸ"""
        regions = []
        current_region = None
        
        for i, line in enumerate(lines):
            line_clean = line.strip()
            if not line_clean:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¨æ ¼è¡Œ
            table_type = self._identify_table_type(line_clean)
            
            if table_type:
                if current_region is None:
                    # å¼€å§‹æ–°çš„è¡¨æ ¼åŒºåŸŸ
                    current_region = {
                        'start_line': i,
                        'end_line': i,
                        'lines': [line_clean],
                        'type': table_type,
                        'confidence': 0.5
                    }
                else:
                    # ç»§ç»­å½“å‰è¡¨æ ¼åŒºåŸŸ
                    current_region['end_line'] = i
                    current_region['lines'].append(line_clean)
                    current_region['confidence'] = min(1.0, current_region['confidence'] + 0.1)
            else:
                if current_region and len(current_region['lines']) >= 2:
                    # ç»“æŸå½“å‰è¡¨æ ¼åŒºåŸŸ
                    regions.append(current_region)
                current_region = None
        
        # å¤„ç†æœ€åä¸€ä¸ªåŒºåŸŸ
        if current_region and len(current_region['lines']) >= 2:
            regions.append(current_region)
        
        return regions
    
    def _identify_table_type(self, line: str) -> Optional[str]:
        """è¯†åˆ«è¡Œçš„è¡¨æ ¼ç±»å‹"""
        for table_type, pattern in self.table_patterns.items():
            if re.search(pattern, line, re.IGNORECASE):
                return table_type
        return None
    
    def _parse_table_region(self, region: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è§£æè¡¨æ ¼åŒºåŸŸ"""
        try:
            table_type = region['type']
            lines = region['lines']
            
            if table_type == 'pipe_table':
                return self._parse_pipe_table(lines)
            elif table_type == 'tab_table':
                return self._parse_tab_table(lines)
            elif table_type == 'colon_table':
                return self._parse_colon_table(lines)
            elif table_type == 'spec_table':
                return self._parse_spec_table(lines)
            else:
                return self._parse_generic_table(lines)
                
        except Exception as e:
            logger.warning(f"Failed to parse table region: {str(e)}")
            return None
    
    def _parse_pipe_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æç®¡é“åˆ†éš”è¡¨æ ¼ |col1|col2|col3|"""
        rows = []
        headers = None
        
        for line in lines:
            # æ¸…ç†ç®¡é“ç¬¦å·
            cells = [cell.strip() for cell in line.split('|') if cell.strip()]
            if not cells:
                continue
                
            # è·³è¿‡åˆ†éš”è¡Œ
            if all(re.match(r'[-\s:]+', cell) for cell in cells):
                continue
                
            if headers is None:
                headers = cells
            else:
                rows.append(cells)
        
        return {
            'type': 'pipe_table',
            'headers': headers or [],
            'rows': rows,
            'column_count': len(headers) if headers else 0,
            'row_count': len(rows)
        }
    
    def _parse_tab_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æåˆ¶è¡¨ç¬¦åˆ†éš”è¡¨æ ¼"""
        rows = []
        headers = None
        
        for line in lines:
            cells = [cell.strip() for cell in line.split('\t') if cell.strip()]
            if not cells:
                continue
                
            if headers is None:
                headers = cells
            else:
                rows.append(cells)
        
        return {
            'type': 'tab_table',
            'headers': headers or [],
            'rows': rows,
            'column_count': len(headers) if headers else 0,
            'row_count': len(rows)
        }
    
    def _parse_colon_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æé”®å€¼å¯¹è¡¨æ ¼ key: value"""
        pairs = {}
        
        for line in lines:
            match = re.match(r'^([^:]+):\s*(.+)$', line.strip())
            if match:
                key = match.group(1).strip()
                value = match.group(2).strip()
                pairs[key] = value
        
        return {
            'type': 'colon_table',
            'pairs': pairs,
            'pair_count': len(pairs)
        }
    
    def _parse_spec_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æè§„æ ¼è¡¨æ ¼å¼"""
        specs = {}
        
        for line in lines:
            # å°è¯•åŒ¹é… "å‚æ•°å å€¼ å•ä½" æ ¼å¼
            parts = line.split()
            if len(parts) >= 2:
                param_name = parts[0]
                value_part = ' '.join(parts[1:])
                
                # å°è¯•åˆ†ç¦»æ•°å€¼å’Œå•ä½
                parsed_value = self._parse_value_with_unit(value_part)
                specs[param_name] = parsed_value
        
        return {
            'type': 'spec_table',
            'specifications': specs,
            'spec_count': len(specs)
        }
    
    def _parse_generic_table(self, lines: List[str]) -> Dict[str, Any]:
        """é€šç”¨è¡¨æ ¼è§£æ"""
        # å°è¯•ç”¨pandasè§£æ
        try:
            text_data = '\n'.join(lines)
            # å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦
            separators = ['\t', '  ', ' ']
            
            for sep in separators:
                try:
                    df = pd.read_csv(StringIO(text_data), sep=sep, engine='python')
                    if len(df.columns) > 1 and len(df) > 0:
                        return {
                            'type': 'generic_table',
                            'headers': df.columns.tolist(),
                            'rows': df.values.tolist(),
                            'column_count': len(df.columns),
                            'row_count': len(df)
                        }
                except:
                    continue
        except:
            pass
        
        # å¤±è´¥æ—¶è¿”å›åŸå§‹è¡Œæ•°æ®
        return {
            'type': 'raw_lines',
            'lines': lines,
            'line_count': len(lines)
        }
    
    def _parse_value_with_unit(self, value_str: str) -> Dict[str, Any]:
        """è§£æå¸¦å•ä½çš„æ•°å€¼"""
        result = {
            'raw_value': value_str,
            'numeric_value': None,
            'unit': '',
            'range': None,
            'tolerance': None
        }
        
        # å°è¯•åŒ¹é…ä¸åŒçš„æ•°å€¼æ¨¡å¼
        for pattern_name, pattern in self.value_patterns.items():
            match = re.search(pattern, value_str, re.IGNORECASE)
            if match:
                if pattern_name == 'number_with_unit':
                    result['numeric_value'] = float(match.group(1))
                    result['unit'] = match.group(2)
                elif pattern_name == 'range_value':
                    result['range'] = {
                        'min': float(match.group(1)),
                        'max': float(match.group(2))
                    }
                elif pattern_name == 'tolerance':
                    result['numeric_value'] = float(match.group(1))
                    result['tolerance'] = float(match.group(2))
                elif pattern_name == 'percentage':
                    result['numeric_value'] = float(match.group(1))
                    result['unit'] = '%'
                elif pattern_name == 'scientific':
                    result['numeric_value'] = float(match.group(1))
                break
        
        return result
    
    def _extract_specifications(self, tables: List[Dict], text_content: str) -> Dict[str, Any]:
        """ä»è§£æçš„è¡¨æ ¼ä¸­æå–è§„æ ¼ä¿¡æ¯"""
        specifications = {}
        
        for table in tables:
            if table['type'] == 'colon_table':
                # é”®å€¼å¯¹è¡¨æ ¼
                for key, value in table.get('pairs', {}).items():
                    spec_info = self._parse_value_with_unit(value)
                    spec_info['source'] = 'colon_table'
                    specifications[key] = spec_info
                    
            elif table['type'] == 'spec_table':
                # è§„æ ¼è¡¨
                for key, value in table.get('specifications', {}).items():
                    value['source'] = 'spec_table'
                    specifications[key] = value
                    
            elif table['type'] in ['pipe_table', 'tab_table', 'generic_table']:
                # ç»“æ„åŒ–è¡¨æ ¼
                headers = table.get('headers', [])
                rows = table.get('rows', [])
                
                # å°è¯•è¯†åˆ«å‚æ•°åˆ—å’Œå€¼åˆ—
                param_col, value_col = self._identify_param_value_columns(headers)
                
                if param_col is not None and value_col is not None:
                    for row in rows:
                        if len(row) > max(param_col, value_col):
                            param_name = row[param_col]
                            param_value = row[value_col]
                            
                            spec_info = self._parse_value_with_unit(param_value)
                            spec_info['source'] = table['type']
                            specifications[param_name] = spec_info
        
        return specifications
    
    def _extract_performance_params(self, tables: List[Dict], text_content: str) -> Dict[str, Any]:
        """æå–æ€§èƒ½å‚æ•°"""
        performance_keywords = [
            'ç²¾åº¦', 'å‡†ç¡®åº¦', 'è¯¯å·®', 'åˆ†è¾¨ç‡', 'å“åº”æ—¶é—´', 'åŠŸè€—', 'æ•ˆç‡',
            'accuracy', 'precision', 'error', 'resolution', 'response', 'power', 'efficiency'
        ]
        
        performance_params = {}
        
        # ä»è§„æ ¼ä¸­ç­›é€‰æ€§èƒ½ç›¸å…³å‚æ•°
        for table in tables:
            if table['type'] == 'colon_table':
                for key, value in table.get('pairs', {}).items():
                    if any(keyword in key.lower() for keyword in performance_keywords):
                        spec_info = self._parse_value_with_unit(value)
                        spec_info['category'] = 'performance'
                        performance_params[key] = spec_info
        
        return performance_params
    
    def _identify_param_value_columns(self, headers: List[str]) -> Tuple[Optional[int], Optional[int]]:
        """è¯†åˆ«å‚æ•°åˆ—å’Œå€¼åˆ—çš„ä½ç½®"""
        param_col = None
        value_col = None
        
        for i, header in enumerate(headers):
            header_lower = header.lower()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå‚æ•°åˆ—
            if any(re.search(pattern, header_lower) for pattern in 
                   list(self.header_patterns['zh']['parameter']) + [self.header_patterns['en']['parameter']]):
                param_col = i
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå€¼åˆ—
            if any(re.search(pattern, header_lower) for pattern in 
                   list(self.header_patterns['zh']['value']) + [self.header_patterns['en']['value']]):
                value_col = i
        
        return param_col, value_col
    
    def _calculate_parsing_confidence(self, tables: List[Dict]) -> float:
        """è®¡ç®—è§£æç½®ä¿¡åº¦"""
        if not tables:
            return 0.0
        
        total_confidence = 0.0
        for table in tables:
            confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
            
            # æ ¹æ®è¡¨æ ¼ç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
            if table['type'] in ['pipe_table', 'tab_table']:
                confidence += 0.3  # ç»“æ„åŒ–è¡¨æ ¼ç½®ä¿¡åº¦æ›´é«˜
            elif table['type'] == 'colon_table':
                confidence += 0.2
            
            # æ ¹æ®æ•°æ®é‡è°ƒæ•´
            data_count = table.get('row_count', table.get('pair_count', table.get('spec_count', 0)))
            if data_count > 5:
                confidence += 0.1
            if data_count > 10:
                confidence += 0.1
            
            total_confidence += min(1.0, confidence)
        
        return total_confidence / len(tables)
    
    def _is_valid_specification(self, spec_name: str, spec_value: str = "") -> bool:
        """
        éªŒè¯è§„æ ¼å‚æ•°æ˜¯å¦æœ‰æ•ˆ - é’ˆå¯¹OCRä¼˜åŒ–ï¼Œå¢å¼ºæ™ºèƒ½è¿‡æ»¤
        
        Args:
            spec_name: è§„æ ¼å‚æ•°åç§°
            spec_value: è§„æ ¼å‚æ•°å€¼ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            bool: æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æŠ€æœ¯è§„æ ¼å‚æ•°
        """
        if not spec_name or not spec_name.strip():
            return False
            
        spec_name = spec_name.strip()
        spec_value = spec_value.strip() if spec_value else ""
        
        # ğŸ”§ é¢„å¤„ç†ï¼šç§»é™¤å¸¸è§çš„OCRé”™è¯¯
        cleaned_name = spec_name.replace('l', '1').replace('O', '0')  # OCRå¸¸è§é”™è¯¯ä¿®æ­£
        
        # ğŸš« ä¸¥æ ¼è¿‡æ»¤æ˜æ˜¾çš„æ— æ•ˆæ¨¡å¼
        for category, patterns in self.invalid_spec_patterns.items():
            for pattern in patterns:
                if re.match(pattern, spec_name, re.IGNORECASE):
                    # ğŸ”§ OCRç‰¹æ®Šå¤„ç†ï¼šå¦‚æœå‚æ•°å€¼åŒ…å«æŠ€æœ¯ä¿¡æ¯ï¼Œä¸è¿‡æ»¤
                    if spec_value and (
                        re.search(r'\d+\s*[VvAaWwHhÎ©â„ƒâ„‰%]', spec_value) or  # æœ‰å•ä½çš„æ•°å€¼
                        re.search(r'(ç”µå‹|ç”µæµ|åŠŸç‡|é¢‘ç‡|voltage|current|power)', spec_value, re.IGNORECASE) or
                        re.search(r'\d+[-~Â±]\d+', spec_value)  # èŒƒå›´å€¼
                    ):
                        logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' åŒ…å«æŠ€æœ¯ä¿¡æ¯ï¼Œä¿ç•™")
                        break
                    else:
                        logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' è¢«è¿‡æ»¤ (ç±»åˆ«: {category}, æ¨¡å¼: {pattern})")
                        return False
        
        # ğŸ” é¢å¤–çš„æ™ºèƒ½éªŒè¯ - æ£€æµ‹å¯èƒ½çš„HYPERLINKæ®‹ç•™
        if re.search(r'HYPERLINK|hyperlink', spec_name + " " + spec_value, re.IGNORECASE):
            logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' åŒ…å«HYPERLINKæ®‹ç•™ï¼Œè¿‡æ»¤")
            return False
        
        # ğŸ” æ£€æµ‹å¯èƒ½çš„æ•°å­—+æ–‡æ¡£æ ¼å¼ç»„åˆï¼ˆå¦‚ "38 HYPERLINK"ï¼‰
        if re.match(r'^\d+\s+(HYPERLINK|PAGE|EMBED|MERGE)', spec_name + " " + spec_value, re.IGNORECASE):
            logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' åŒ¹é…æ•°å­—+æ–‡æ¡£æ ¼å¼æ¨¡å¼ï¼Œè¿‡æ»¤")
            return False
        
        # âœ… æ£€æŸ¥æ˜¯å¦åŒ¹é…æœ‰æ•ˆæ¨¡å¼
        combined_text = spec_name + " " + spec_value
        for pattern in self.valid_spec_patterns:
            if re.search(pattern, combined_text, re.IGNORECASE):
                return True
        
        # ğŸ” OCRä¼˜åŒ–çš„é¢å¤–éªŒè¯é€»è¾‘
        # 1. åŒ…å«æ•°å­—å’Œä¸­æ–‡/è‹±æ–‡å­—ç¬¦çš„ç»„åˆ
        has_digit = bool(re.search(r'\d', combined_text))
        has_chinese = bool(re.search(r'[\u4e00-\u9fff]', spec_name))
        has_english = bool(re.search(r'[a-zA-Z]{2,}', spec_name))
        has_reasonable_length = 1 <= len(spec_name) <= 25  # ğŸ”§ æ”¾å®½é•¿åº¦é™åˆ¶
        
        if has_digit and (has_chinese or has_english) and has_reasonable_length:
            logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' é€šè¿‡æ•°å­—+æ–‡å­—éªŒè¯")
            return True
        
        # 2. æ£€æŸ¥æŠ€æœ¯å•ä½å’Œæµ‹é‡å€¼
        has_unit_pattern = bool(re.search(r'[0-9]+[\s]*[a-zA-Z%Â°â„ƒÎ©]+', combined_text))
        if has_unit_pattern:
            logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' é€šè¿‡å•ä½æ¨¡å¼éªŒè¯")
            return True
        
        # 3. æ£€æŸ¥æŠ€æœ¯å…³é”®è¯ï¼ˆæ›´å®½æ¾ï¼‰
        technical_keywords = [
            'ç”µ', 'æµ', 'å‹', 'åŠŸ', 'ç‡', 'é¢‘', 'æ¸©', 'åº¦', 'ç²¾', 'é‡', 'æµ‹', 'è¯•', 'ä¿', 'æŠ¤',
            'volt', 'amp', 'watt', 'freq', 'temp', 'test', 'prot', 'meas', 'spec', 'param'
        ]
        
        for keyword in technical_keywords:
            if keyword in spec_name.lower() or keyword in spec_value.lower():
                logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' é€šè¿‡æŠ€æœ¯å…³é”®è¯éªŒè¯: {keyword}")
                return True
        
        # 4. OCRå¸¸è§æƒ…å†µï¼šçŸ­çš„æŠ€æœ¯å‚æ•°åç§°
        if 2 <= len(spec_name) <= 8 and (has_chinese or has_english) and spec_value:
            # å¦‚æœå‚æ•°åå¾ˆçŸ­ä½†æœ‰å€¼ï¼Œä¸”å€¼çœ‹èµ·æ¥åƒæŠ€æœ¯æ•°æ®
            if re.search(r'[\d\.]+|[a-zA-Z]+|[\u4e00-\u9fff]+', spec_value):
                logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' é€šè¿‡çŸ­å‚æ•°å+æœ‰æ•ˆå€¼éªŒè¯")
                return True
            
        logger.debug(f"è§„æ ¼å‚æ•° '{spec_name}' = '{spec_value}' æœªé€šè¿‡éªŒè¯")
        return False
    
    def _clean_specification_data(self, specifications: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ¸…ç†è§„æ ¼å‚æ•°æ•°æ®ï¼Œç§»é™¤æ— æ•ˆé¡¹ç›®
        
        Args:
            specifications: åŸå§‹è§„æ ¼å‚æ•°å­—å…¸
            
        Returns:
            Dict: æ¸…ç†åçš„è§„æ ¼å‚æ•°å­—å…¸
        """
        cleaned_specs = {}
        filtered_count = 0
        
        for spec_name, spec_data in specifications.items():
            # è·å–è§„æ ¼å€¼ç”¨äºéªŒè¯
            spec_value = ""
            if isinstance(spec_data, dict):
                spec_value = spec_data.get('value', '') or spec_data.get('raw_value', '')
            elif isinstance(spec_data, str):
                spec_value = spec_data
            
            # éªŒè¯è§„æ ¼å‚æ•°
            if self._is_valid_specification(spec_name, str(spec_value)):
                cleaned_specs[spec_name] = spec_data
            else:
                filtered_count += 1
                logger.debug(f"è¿‡æ»¤æ— æ•ˆè§„æ ¼å‚æ•°: {spec_name} = {spec_value}")
        
        if filtered_count > 0:
            logger.info(f"è§„æ ¼å‚æ•°æ¸…ç†å®Œæˆï¼šä¿ç•™ {len(cleaned_specs)} é¡¹ï¼Œè¿‡æ»¤ {filtered_count} é¡¹æ— æ•ˆå‚æ•°")
        
        return cleaned_specs

    def enhance_extraction_with_tables(self, base_extraction: Dict[str, Any], 
                                     text_content: str) -> Dict[str, Any]:
        """ç”¨è¡¨æ ¼è§£æç»“æœå¢å¼ºåŸºç¡€æå–"""
        try:
            # è§£æè¡¨æ ¼
            table_results = self.parse_document_tables(text_content)
            
            # ğŸ”§ åˆå¹¶è§„æ ¼ä¿¡æ¯ - æ·»åŠ æ•°æ®æ¸…ç†
            enhanced_specs = base_extraction.get('specifications', {}).copy()
            
            # å…ˆæ¸…ç†åŸºç¡€æå–çš„è§„æ ¼æ•°æ®
            enhanced_specs = self._clean_specification_data(enhanced_specs)
            
            # æ¸…ç†è¡¨æ ¼æå–çš„è§„æ ¼æ•°æ®
            table_specs = self._clean_specification_data(table_results.get('specifications', {}))
            
            for spec_name, spec_data in table_specs.items():
                if spec_name not in enhanced_specs:
                    # è½¬æ¢æ ¼å¼ä»¥åŒ¹é…åŸºç¡€æå–æ ¼å¼
                    enhanced_specs[spec_name] = {
                        'value': spec_data.get('raw_value', ''),
                        'unit': spec_data.get('unit', ''),
                        'description': f"ä»{spec_data.get('source', 'è¡¨æ ¼')}ä¸­æå–"
                    }
                    
                    # å¦‚æœæœ‰æ•°å€¼ï¼Œæ·»åŠ æ•°å€¼ä¿¡æ¯
                    if spec_data.get('numeric_value') is not None:
                        enhanced_specs[spec_name]['numeric_value'] = spec_data['numeric_value']
                    
                    # å¦‚æœæœ‰èŒƒå›´ï¼Œæ·»åŠ èŒƒå›´ä¿¡æ¯
                    if spec_data.get('range'):
                        enhanced_specs[spec_name]['range'] = spec_data['range']
                    
                    # å¦‚æœæœ‰å®¹å·®ï¼Œæ·»åŠ å®¹å·®ä¿¡æ¯
                    if spec_data.get('tolerance'):
                        enhanced_specs[spec_name]['tolerance'] = spec_data['tolerance']
            
            # æ›´æ–°åŸºç¡€æå–ç»“æœ
            enhanced_extraction = base_extraction.copy()
            enhanced_extraction['specifications'] = enhanced_specs
            
            # æ·»åŠ è¡¨æ ¼è§£æå…ƒæ•°æ®
            enhanced_extraction['table_parsing'] = {
                'tables_found': table_results.get('tables_found', 0),
                'parsing_confidence': table_results.get('parsing_confidence', 0.0),
                'performance_params_count': len(table_results.get('performance_parameters', {}))
            }
            
            logger.info(f"Enhanced extraction with {len(enhanced_specs)} specifications from tables")
            return enhanced_extraction
            
        except Exception as e:
            logger.error(f"Table enhancement failed: {str(e)}")
            return base_extraction