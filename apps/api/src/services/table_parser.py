# -*- coding: utf-8 -*-
"""
å¤æ‚è¡¨æ ¼è§£ææœåŠ¡
ä¸“é—¨å¤„ç†å„ç§æ ¼å¼çš„è§„æ ¼è¡¨ã€å‚æ•°è¡¨ç­‰ç»“æ„åŒ–æ•°æ®
"""
import re
import logging
from typing import Dict, List, Any, Tuple, Optional
import pandas as pd
from io import StringIO

logger = logging.getLogger(__name__)

class TableParser:
    """å¤æ‚è¡¨æ ¼è§£æå™¨"""
    
    def __init__(self):
        # è¡¨æ ¼è¯†åˆ«æ¨¡å¼
        self.table_patterns = {
            'pipe_table': r'\|.*\|',  # |column1|column2|
            'tab_table': r'.*\t.*\t.*',  # tabåˆ†éš”
            'colon_table': r'.*:\s*.*',  # é”®å€¼å¯¹ key: value
            'dash_table': r'[-\s]*[-]+[-\s]*',  # åˆ†éš”çº¿
            'spec_table': r'^\s*[^\s]+\s+[^\s]+.*$',  # è§„æ ¼è¡¨æ ¼å¼
        }
        
        # ğŸš« æ— æ•ˆè§„æ ¼å‚æ•°è¿‡æ»¤æ¨¡å¼ - å¢å¼ºè¿‡æ»¤ç­–ç•¥ï¼Œé’ˆå¯¹æˆªå›¾ä¸­çš„å¥‡æ€ªæ•°æ®
        self.invalid_spec_patterns = {
            # Wordæ–‡æ¡£å†…éƒ¨æ ¼å¼ - ä¿ç•™HYPERLINKè¿‡æ»¤ä½†å‡å°‘è¯¯æ€
            'word_format': [
                r'^(EMBED|MERGEFORMAT|CERTIFICATE|PACKING)$',
                r'^(PBrush|Word\.Picture|OF CONFORMITY|LIST DATE).*',
                r'.*EMBED.*',
                r'.*\.Picture\.',
                # ğŸ”§ å¢å¼ºHYPERLINKè¿‡æ»¤ï¼Œå¤„ç†å¤åˆæ ¼å¼
                r'^HYPERLINK$',  # åªè¿‡æ»¤çº¯HYPERLINK
                r'^\d+\s+HYPERLINK\s*$',  # åªè¿‡æ»¤ "æ•°å­— HYPERLINK" ä¸”åé¢æ²¡æœ‰å…¶ä»–å†…å®¹
                r'^HYPERLINK\s+["\'].*["\']$',  # è¿‡æ»¤ HYPERLINK "url" æ ¼å¼
                r'^[a-z]+\s+\d+\s+HYPERLINK.*$',  # å¤„ç† "h 9 HYPERLINK HYPE" ç±»å‹
                r'.*HYPERLINK\s+HYPE.*'  # å¤„ç†æˆªæ–­çš„HYPERLINK
            ],
            # ğŸ†• é¡µé¢å’Œæ–‡æ¡£ç»“æ„å…ƒç´  - é’ˆå¯¹ "PAGE 7" ç­‰é—®é¢˜
            'page_elements': [
                r'^PAGE\s+\d+$',  # ç²¾ç¡®åŒ¹é… "PAGE 7" æ ¼å¼  
                r'^ç¬¬\s*\d+\s*é¡µ$',  # ä¸­æ–‡é¡µç 
                r'^é¡µ\s*\d+$',  # ç®€åŒ–é¡µç 
                r'^\d+\s*é¡µ$',  # æ•°å­—é¡µ
                r'^(CHAPTER|SECTION)\s+\d+$',  # ç« èŠ‚æ ‡è®°
                r'^(ç›®å½•|ç´¢å¼•|é¡µç |ç« èŠ‚|æ ‡é¢˜)$',
                r'^(CONTENTS|INDEX|TITLE)$'
            ],
            # æ–‡æ¡£ç»“æ„æ ‡è¯† - å‡å°‘å•å­—ç¬¦è¿‡æ»¤çš„è¯¯æ€
            'doc_structure': [
                r'^(Toc\d+|_Toc|_Ref).*',
                r'.*Toc\d+.*',
                r'^\d+$'  # åªè¿‡æ»¤çº¯æ•°å­—
            ],
            # ğŸ†• è¡¨æ ¼æ ¼å¼å™ªå£° - é’ˆå¯¹ "A A AB X B", "Ca a a a b" ç­‰é—®é¢˜
            'table_format_noise': [
                # å¤„ç†è¡¨æ ¼è¾¹æ¡†å’Œæ ¼å¼åŒ–ç¬¦å·è¢«è¯¯è¯†åˆ«çš„æƒ…å†µ
                r'^[A-Z]\s+[A-Z]\s+[A-Z][A-Z]?\s+[A-Z]\s+[A-Z]$',  # "A A AB X B" ç±»å‹
                r'^[A-Z][a-z]?\s+[a-z]\s+[a-z]\s+[a-z]\s+[a-z]$',  # "Ca a a a b" ç±»å‹
                r'^[A-Z]{1,2}\s+[A-Z]{1,2}\s+[A-Z]{1,2}.*[A-Z]\s+[A-Z]$',  # ç±»ä¼¼çš„å¤§å†™å­—æ¯ç»„åˆ
                r'^[a-z]+\s+[a-z]\s+[a-z].*[a-z]\s+[a-z]$',  # ç±»ä¼¼çš„å°å†™å­—æ¯ç»„åˆ
                # è¡¨æ ¼è¾¹æ¡†çº¿è¢«è¯¯è¯†åˆ«
                r'^[\|\s\-\+\=]{3,}$',  # è¡¨æ ¼è¾¹æ¡†çº¿
                r'^[â”‚â”Œâ”â””â”˜â”œâ”¤â”¬â”´â”¼]{2,}$',  # Unicodeè¡¨æ ¼è¾¹æ¡†å­—ç¬¦
                r'^\s*[ï½œ\|]\s*$',  # å•ç‹¬çš„ç®¡é“ç¬¦
                r'^\s*[\-]{2,}\s*$',  # è¿å­—ç¬¦åˆ†éš”çº¿
            ],
            # æ ¼å¼åŒ–å­—ç¬¦å’Œæ§åˆ¶å­—ç¬¦
            'format_chars': [
                r'^[\s\-_=]{3,}$',  # åªè¿‡æ»¤3ä¸ªä»¥ä¸Šè¿ç»­æ ¼å¼å­—ç¬¦
                r'^[^\w\u4e00-\u9fff]+$',  # åªæœ‰éæ–‡å­—å­—ç¬¦
                r'.*[\x00-\x1f\x7f-\x9f].*'  # æ§åˆ¶å­—ç¬¦
            ],
            # ğŸ†• æ˜ç¡®çš„åƒåœ¾å†…å®¹æ¨¡å¼
            'obvious_garbage': [
                r'^[^a-zA-Z\u4e00-\u9fff\d]*$',  # å®Œå…¨æ²¡æœ‰æ–‡å­—å’Œæ•°å­—çš„å†…å®¹
                r'^\s*$',  # ç©ºç™½å†…å®¹
                r'^(.)\1{4,}$',  # åŒä¸€å­—ç¬¦é‡å¤5æ¬¡ä»¥ä¸Š
                # å•ä¸ªæ— æ„ä¹‰å­—ç¬¦æˆ–å­—ç¬¦ç»„åˆ
                r'^[a-zA-Z]{1}$',  # å•ä¸ªå­—æ¯ï¼ˆé™¤éåœ¨æŠ€æœ¯ä¸Šä¸‹æ–‡ä¸­ï¼‰
                r'^[a-zA-Z]\s+$',  # å•ä¸ªå­—æ¯åŠ ç©ºæ ¼
            ]
        }
        
        # âœ… æœ‰æ•ˆæŠ€æœ¯è§„æ ¼æ ‡è¯†æ¨¡å¼ - é’ˆå¯¹ç”µåŠ›è®¾å¤‡æ–‡æ¡£ä¼˜åŒ–
        self.valid_spec_patterns = [
            # ä¸­æ–‡æŠ€æœ¯å‚æ•° - ä¸“é—¨é’ˆå¯¹ç”µåŠ›æµ‹è¯•è®¾å¤‡æ‰©å±•
            r'(ç”µå‹|ç”µæµ|åŠŸç‡|é¢‘ç‡|æ¸©åº¦|æ¹¿åº¦|ç²¾åº¦|èŒƒå›´|å®¹é‡|é€Ÿåº¦|æ—¶é—´|å‹åŠ›|æµé‡|é˜»æŠ—|ç›¸æ•°|è¾“å‡º|è¾“å…¥)',
            r'(å·¥ä½œ|é¢å®š|æœ€å¤§|æœ€å°|æ ‡å‡†|æµ‹é‡|æµ‹è¯•|æ£€æµ‹|ä¿æŠ¤|æ§åˆ¶|æ˜¾ç¤º|é€šä¿¡|æ¥å£|å°ºå¯¸|é‡é‡|è´Ÿè½½)',
            r'(ç»§ç”µ|ä¿æŠ¤|è£…ç½®|è®¾å¤‡|ä»ªå™¨|ä»ªè¡¨|æ¨¡å—|å•å…ƒ|ç³»ç»Ÿ|å›è·¯|ç”µè·¯|å˜å‹å™¨|å˜æ¯”|ç»„åˆ«)',
            # ğŸ†• ä¸“é—¨é’ˆå¯¹å˜æ¯”æµ‹è¯•ä»ªç­‰ç”µåŠ›è®¾å¤‡çš„å…³é”®è¯
            r'(å˜æ¯”|ç»„åˆ«|æµ‹è¯•ä»ª|æ£€æµ‹ä»ª|ä¿æŠ¤|ç»§ç”µ|ç”µåŠ›|é«˜å‹|ä½å‹|ç»ç¼˜|è€å‹|æµ‹è¯•|æ ¡éªŒ)',
            r'(äº’æ„Ÿå™¨|CT|PT|å¼€å…³|æ–­è·¯å™¨|æ¥è§¦å™¨|ç”µæŠ—å™¨|ç”µå®¹å™¨|é¿é›·å™¨)',
            # è‹±æ–‡æŠ€æœ¯å‚æ•° - æ‰©å±•ç”µåŠ›è®¾å¤‡è¯æ±‡
            r'(voltage|current|power|frequency|temperature|humidity|accuracy|range|capacity)',
            r'(speed|time|pressure|flow|impedance|phase|output|input|working|rated|max|min)',
            r'(relay|protection|device|equipment|instrument|module|unit|system|circuit)',
            r'(transformer|ratio|test|high|low|insulation|withstand|measurement)',
            # å•ä½æ¨¡å¼ - æ‰©å±•ç”µåŠ›è®¾å¤‡å¸¸ç”¨å•ä½
            r'.*[VvAaWwHhÎ©â„ƒâ„‰%mMkKgGÎ©]+.*',
            r'.*[0-9]+\s*[VvAaWwHhÎ©â„ƒâ„‰%mMkKgGÎ¨Ï„].*',  # æ•°å­—+å•ä½ï¼Œå¢åŠ ç”µåŠ›å•ä½
            r'.*[0-9]+\s*(kV|kA|MW|kW|Hz|Î©|Â°C|Â°F).*',  # å¸¸è§ç”µåŠ›å•ä½
            # æ•°å€¼æ¨¡å¼ - æ›´å®½æ¾çš„æ•°å€¼è¯†åˆ«
            r'.*\d+.*',
            r'.*[0-9]+[\.,][0-9]+.*',  # å°æ•°
            r'.*[0-9]+\s*[-~Â±]\s*[0-9]+.*',  # èŒƒå›´å€¼
            r'.*[0-9]+\s*[xXÃ—]\s*[0-9]+.*',  # å€æ•°å…³ç³»
            # æ¯”å€¼å’Œåˆ†æ•°æ¨¡å¼ï¼ˆå˜æ¯”æµ‹è¯•ä»ªå¸¸è§ï¼‰
            r'.*[0-9]+\s*[:/]\s*[0-9]+.*',  # æ¯”å€¼å¦‚ 220:110
            r'.*[0-9]+/[0-9]+.*',  # åˆ†æ•°
            # OCRå¸¸è§çš„æŠ€æœ¯è¯æ±‡ï¼ˆåŒ…æ‹¬å¯èƒ½çš„è¯†åˆ«é”™è¯¯ï¼‰
            r'.*(æµ‹è¯•|æ£€æµ‹|ä¿æŠ¤|ç»§ç”µ|è£…ç½®|è®¾å¤‡|æ€§èƒ½|å‚æ•°|è§„æ ¼|æŒ‡æ ‡|é…ç½®|ç‰¹æ€§).*',
            r'.*(test|protect|relay|device|spec|param|performance|config|feature).*',
            # ğŸ†• ç‰¹æ®Šæ¨¡å¼ï¼šçŸ­æŠ€æœ¯å‚æ•°åï¼ˆå¸¸è§äºè¡¨æ ¼ï¼‰
            r'^[A-Z]{2,5}$',  # å¦‚ ACã€DCã€RS485ç­‰æŠ€æœ¯ç¼©å†™
            r'^[a-z]{2,8}$',  # å°å†™æŠ€æœ¯å‚æ•°
            r'^\w{1,3}\d+$',   # å¦‚ V1ã€A2ã€f0ç­‰å‚æ•°ç¼–å·
            # ğŸ†• åŒ…å«æ•°å­—å’Œå­—æ¯çš„æ··åˆæ¨¡å¼
            r'^[a-zA-Z\u4e00-\u9fff]+\d+[a-zA-Z\u4e00-\u9fff]*$',  # å¦‚ é¢‘ç‡1ã€ç”µå‹Aç­‰
            r'^\d+[a-zA-Z\u4e00-\u9fff]+$'  # å¦‚ 3ç›¸ã€220Vç­‰
        ]
        
        # å¸¸è§è¡¨å¤´è¯†åˆ«
        self.header_patterns = {
            'zh': {
                'parameter': r'(å‚æ•°|è§„æ ¼|æŒ‡æ ‡|é¡¹ç›®|åç§°)',
                'value': r'(å€¼|æ•°å€¼|å‚æ•°å€¼|è§„æ ¼å€¼)',
                'unit': r'(å•ä½|é‡çº²)',
                'description': r'(è¯´æ˜|æè¿°|å¤‡æ³¨|æ³¨é‡Š)',
                'range': r'(èŒƒå›´|åŒºé—´|é™å€¼)',
                'condition': r'(æ¡ä»¶|ç¯å¢ƒ|çŠ¶æ€)'
            },
            'en': {
                'parameter': r'(parameter|specification|spec|item|name)',
                'value': r'(value|val|data)',
                'unit': r'(unit|dimension)',
                'description': r'(description|desc|note|remark)',
                'range': r'(range|limit)',
                'condition': r'(condition|environment|state)'
            }
        }
        
        # æ•°å€¼å’Œå•ä½è¯†åˆ«æ¨¡å¼
        self.value_patterns = {
            'number_with_unit': r'([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\s*([a-zA-ZÂ°â„ƒâ„‰%Î©]+)',
            'range_value': r'([-+]?\d*\.?\d+)\s*[-~]\s*([-+]?\d*\.?\d+)',
            'tolerance': r'([-+]?\d*\.?\d+)\s*[Â±]\s*([-+]?\d*\.?\d+)',
            'percentage': r'([-+]?\d*\.?\d+)\s*%',
            'scientific': r'([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)',
        }
    
    def parse_document_tables(self, text_content: str) -> Dict[str, Any]:
        """
        ä»æ–‡æ¡£ä¸­è§£ææ‰€æœ‰è¡¨æ ¼
        
        Args:
            text_content: æ–‡æ¡£æ–‡æœ¬å†…å®¹
            
        Returns:
            Dict: è§£æç»“æœ
        """
        try:
            # æŒ‰è¡Œåˆ†å‰²æ–‡æœ¬
            lines = text_content.split('\n')
            
            # è¯†åˆ«è¡¨æ ¼åŒºåŸŸ
            table_regions = self._identify_table_regions(lines)
            
            # è§£ææ¯ä¸ªè¡¨æ ¼åŒºåŸŸ
            parsed_tables = []
            for region in table_regions:
                table_data = self._parse_table_region(region)
                if table_data:
                    parsed_tables.append(table_data)
            
            # æå–è§„æ ¼ä¿¡æ¯
            specifications = self._extract_specifications(parsed_tables, text_content)
            
            # æå–æ€§èƒ½å‚æ•°
            performance_params = self._extract_performance_params(parsed_tables, text_content)
            
            result = {
                'tables_found': len(parsed_tables),
                'specifications': specifications,
                'performance_parameters': performance_params,
                'raw_tables': parsed_tables,
                'parsing_confidence': self._calculate_parsing_confidence(parsed_tables)
            }
            
            logger.info(f"Parsed {len(parsed_tables)} tables with {len(specifications)} specifications")
            return result
            
        except Exception as e:
            logger.error(f"Table parsing failed: {str(e)}")
            return {
                'tables_found': 0,
                'specifications': {},
                'performance_parameters': {},
                'raw_tables': [],
                'parsing_confidence': 0.0,
                'error': str(e)
            }
    
    def _identify_table_regions(self, lines: List[str]) -> List[Dict[str, Any]]:
        """è¯†åˆ«æ–‡æœ¬ä¸­çš„è¡¨æ ¼åŒºåŸŸ"""
        regions = []
        current_region = None
        
        for i, line in enumerate(lines):
            line_clean = line.strip()
            if not line_clean:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¨æ ¼è¡Œ
            table_type = self._identify_table_type(line_clean)
            
            if table_type:
                if current_region is None:
                    # å¼€å§‹æ–°çš„è¡¨æ ¼åŒºåŸŸ
                    current_region = {
                        'start_line': i,
                        'end_line': i,
                        'lines': [line_clean],
                        'type': table_type,
                        'confidence': 0.5
                    }
                else:
                    # ç»§ç»­å½“å‰è¡¨æ ¼åŒºåŸŸ
                    current_region['end_line'] = i
                    current_region['lines'].append(line_clean)
                    current_region['confidence'] = min(1.0, current_region['confidence'] + 0.1)
            else:
                if current_region and len(current_region['lines']) >= 2:
                    # ç»“æŸå½“å‰è¡¨æ ¼åŒºåŸŸ
                    regions.append(current_region)
                current_region = None
        
        # å¤„ç†æœ€åä¸€ä¸ªåŒºåŸŸ
        if current_region and len(current_region['lines']) >= 2:
            regions.append(current_region)
        
        return regions
    
    def _identify_table_type(self, line: str) -> Optional[str]:
        """è¯†åˆ«è¡Œçš„è¡¨æ ¼ç±»å‹"""
        for table_type, pattern in self.table_patterns.items():
            if re.search(pattern, line, re.IGNORECASE):
                return table_type
        return None
    
    def _parse_table_region(self, region: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è§£æè¡¨æ ¼åŒºåŸŸ"""
        try:
            table_type = region['type']
            lines = region['lines']
            
            if table_type == 'pipe_table':
                return self._parse_pipe_table(lines)
            elif table_type == 'tab_table':
                return self._parse_tab_table(lines)
            elif table_type == 'colon_table':
                return self._parse_colon_table(lines)
            elif table_type == 'spec_table':
                return self._parse_spec_table(lines)
            else:
                return self._parse_generic_table(lines)
                
        except Exception as e:
            logger.warning(f"Failed to parse table region: {str(e)}")
            return None
    
    def _parse_pipe_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æç®¡é“åˆ†éš”è¡¨æ ¼ |col1|col2|col3|"""
        rows = []
        headers = None
        
        for line in lines:
            # æ¸…ç†ç®¡é“ç¬¦å·
            cells = [cell.strip() for cell in line.split('|') if cell.strip()]
            if not cells:
                continue
                
            # è·³è¿‡åˆ†éš”è¡Œ
            if all(re.match(r'[-\s:]+', cell) for cell in cells):
                continue
                
            if headers is None:
                headers = cells
            else:
                rows.append(cells)
        
        return {
            'type': 'pipe_table',
            'headers': headers or [],
            'rows': rows,
            'column_count': len(headers) if headers else 0,
            'row_count': len(rows)
        }
    
    def _parse_tab_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æåˆ¶è¡¨ç¬¦åˆ†éš”è¡¨æ ¼"""
        rows = []
        headers = None
        
        for line in lines:
            cells = [cell.strip() for cell in line.split('\t') if cell.strip()]
            if not cells:
                continue
                
            if headers is None:
                headers = cells
            else:
                rows.append(cells)
        
        return {
            'type': 'tab_table',
            'headers': headers or [],
            'rows': rows,
            'column_count': len(headers) if headers else 0,
            'row_count': len(rows)
        }
    
    def _parse_colon_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æé”®å€¼å¯¹è¡¨æ ¼ key: value"""
        pairs = {}
        
        for line in lines:
            match = re.match(r'^([^:]+):\s*(.+)$', line.strip())
            if match:
                key = match.group(1).strip()
                value = match.group(2).strip()
                pairs[key] = value
        
        return {
            'type': 'colon_table',
            'pairs': pairs,
            'pair_count': len(pairs)
        }
    
    def _parse_spec_table(self, lines: List[str]) -> Dict[str, Any]:
        """è§£æè§„æ ¼è¡¨æ ¼å¼"""
        specs = {}
        
        for line in lines:
            # å°è¯•åŒ¹é… "å‚æ•°å å€¼ å•ä½" æ ¼å¼
            parts = line.split()
            if len(parts) >= 2:
                param_name = parts[0]
                value_part = ' '.join(parts[1:])
                
                # å°è¯•åˆ†ç¦»æ•°å€¼å’Œå•ä½
                parsed_value = self._parse_value_with_unit(value_part)
                specs[param_name] = parsed_value
        
        return {
            'type': 'spec_table',
            'specifications': specs,
            'spec_count': len(specs)
        }
    
    def _parse_generic_table(self, lines: List[str]) -> Dict[str, Any]:
        """é€šç”¨è¡¨æ ¼è§£æ"""
        # å°è¯•ç”¨pandasè§£æ
        try:
            text_data = '\n'.join(lines)
            # å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦
            separators = ['\t', '  ', ' ']
            
            for sep in separators:
                try:
                    df = pd.read_csv(StringIO(text_data), sep=sep, engine='python')
                    if len(df.columns) > 1 and len(df) > 0:
                        return {
                            'type': 'generic_table',
                            'headers': df.columns.tolist(),
                            'rows': df.values.tolist(),
                            'column_count': len(df.columns),
                            'row_count': len(df)
                        }
                except:
                    continue
        except:
            pass
        
        # å¤±è´¥æ—¶è¿”å›åŸå§‹è¡Œæ•°æ®
        return {
            'type': 'raw_lines',
            'lines': lines,
            'line_count': len(lines)
        }
    
    def _parse_value_with_unit(self, value_str: str) -> Dict[str, Any]:
        """è§£æå¸¦å•ä½çš„æ•°å€¼"""
        result = {
            'raw_value': value_str,
            'numeric_value': None,
            'unit': '',
            'range': None,
            'tolerance': None
        }
        
        # å°è¯•åŒ¹é…ä¸åŒçš„æ•°å€¼æ¨¡å¼
        for pattern_name, pattern in self.value_patterns.items():
            match = re.search(pattern, value_str, re.IGNORECASE)
            if match:
                if pattern_name == 'number_with_unit':
                    result['numeric_value'] = float(match.group(1))
                    result['unit'] = match.group(2)
                elif pattern_name == 'range_value':
                    result['range'] = {
                        'min': float(match.group(1)),
                        'max': float(match.group(2))
                    }
                elif pattern_name == 'tolerance':
                    result['numeric_value'] = float(match.group(1))
                    result['tolerance'] = float(match.group(2))
                elif pattern_name == 'percentage':
                    result['numeric_value'] = float(match.group(1))
                    result['unit'] = '%'
                elif pattern_name == 'scientific':
                    result['numeric_value'] = float(match.group(1))
                break
        
        return result
    
    def _extract_specifications(self, tables: List[Dict], text_content: str) -> Dict[str, Any]:
        """ä»è§£æçš„è¡¨æ ¼ä¸­æå–è§„æ ¼ä¿¡æ¯"""
        specifications = {}
        
        for table in tables:
            if table['type'] == 'colon_table':
                # é”®å€¼å¯¹è¡¨æ ¼
                for key, value in table.get('pairs', {}).items():
                    spec_info = self._parse_value_with_unit(value)
                    spec_info['source'] = 'colon_table'
                    specifications[key] = spec_info
                    
            elif table['type'] == 'spec_table':
                # è§„æ ¼è¡¨
                for key, value in table.get('specifications', {}).items():
                    value['source'] = 'spec_table'
                    specifications[key] = value
                    
            elif table['type'] in ['pipe_table', 'tab_table', 'generic_table']:
                # ç»“æ„åŒ–è¡¨æ ¼
                headers = table.get('headers', [])
                rows = table.get('rows', [])
                
                # å°è¯•è¯†åˆ«å‚æ•°åˆ—å’Œå€¼åˆ—
                param_col, value_col = self._identify_param_value_columns(headers)
                
                if param_col is not None and value_col is not None:
                    for row in rows:
                        if len(row) > max(param_col, value_col):
                            param_name = row[param_col]
                            param_value = row[value_col]
                            
                            spec_info = self._parse_value_with_unit(param_value)
                            spec_info['source'] = table['type']
                            specifications[param_name] = spec_info
        
        return specifications
    
    def _extract_performance_params(self, tables: List[Dict], text_content: str) -> Dict[str, Any]:
        """æå–æ€§èƒ½å‚æ•°"""
        performance_keywords = [
            'ç²¾åº¦', 'å‡†ç¡®åº¦', 'è¯¯å·®', 'åˆ†è¾¨ç‡', 'å“åº”æ—¶é—´', 'åŠŸè€—', 'æ•ˆç‡',
            'accuracy', 'precision', 'error', 'resolution', 'response', 'power', 'efficiency'
        ]
        
        performance_params = {}
        
        # ä»è§„æ ¼ä¸­ç­›é€‰æ€§èƒ½ç›¸å…³å‚æ•°
        for table in tables:
            if table['type'] == 'colon_table':
                for key, value in table.get('pairs', {}).items():
                    if any(keyword in key.lower() for keyword in performance_keywords):
                        spec_info = self._parse_value_with_unit(value)
                        spec_info['category'] = 'performance'
                        performance_params[key] = spec_info
        
        return performance_params
    
    def _identify_param_value_columns(self, headers: List[str]) -> Tuple[Optional[int], Optional[int]]:
        """è¯†åˆ«å‚æ•°åˆ—å’Œå€¼åˆ—çš„ä½ç½®"""
        param_col = None
        value_col = None
        
        for i, header in enumerate(headers):
            header_lower = header.lower()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå‚æ•°åˆ—
            if any(re.search(pattern, header_lower) for pattern in 
                   list(self.header_patterns['zh']['parameter']) + [self.header_patterns['en']['parameter']]):
                param_col = i
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå€¼åˆ—
            if any(re.search(pattern, header_lower) for pattern in 
                   list(self.header_patterns['zh']['value']) + [self.header_patterns['en']['value']]):
                value_col = i
        
        return param_col, value_col
    
    def _calculate_parsing_confidence(self, tables: List[Dict]) -> float:
        """è®¡ç®—è§£æç½®ä¿¡åº¦"""
        if not tables:
            return 0.0
        
        total_confidence = 0.0
        for table in tables:
            confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
            
            # æ ¹æ®è¡¨æ ¼ç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
            if table['type'] in ['pipe_table', 'tab_table']:
                confidence += 0.3  # ç»“æ„åŒ–è¡¨æ ¼ç½®ä¿¡åº¦æ›´é«˜
            elif table['type'] == 'colon_table':
                confidence += 0.2
            
            # æ ¹æ®æ•°æ®é‡è°ƒæ•´
            data_count = table.get('row_count', table.get('pair_count', table.get('spec_count', 0)))
            if data_count > 5:
                confidence += 0.1
            if data_count > 10:
                confidence += 0.1
            
            total_confidence += min(1.0, confidence)
        
        return total_confidence / len(tables)
    
    def _is_valid_specification(self, spec_name: str, spec_value: str = "") -> bool:
        """
        éªŒè¯è§„æ ¼å‚æ•°æ˜¯å¦æœ‰æ•ˆ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘è¯¯æ€ï¼Œå¢åŠ è°ƒè¯•ä¿¡æ¯
        
        Args:
            spec_name: è§„æ ¼å‚æ•°åç§°
            spec_value: è§„æ ¼å‚æ•°å€¼ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            bool: æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æŠ€æœ¯è§„æ ¼å‚æ•°
        """
        if not spec_name or not spec_name.strip():
            return False
            
        spec_name = spec_name.strip()
        spec_value = spec_value.strip() if spec_value else ""
        
        # ğŸ”§ é¢„å¤„ç†ï¼šç§»é™¤å¸¸è§çš„OCRé”™è¯¯
        cleaned_name = spec_name.replace('l', '1').replace('O', '0')
        combined_text = spec_name + " " + spec_value
        
        # ğŸš¨ ä¼˜å…ˆçº§1: å¦‚æœå‚æ•°å€¼æ˜ç¡®åŒ…å«æŠ€æœ¯ä¿¡æ¯ï¼Œç›´æ¥é€šè¿‡
        if spec_value and self._contains_technical_info(spec_value):
            logger.debug(f"âœ… è§„æ ¼å‚æ•° '{spec_name}' = '{spec_value}' åŒ…å«æ˜ç¡®æŠ€æœ¯ä¿¡æ¯ï¼Œç›´æ¥é€šè¿‡")
            return True
        
        # ğŸš¨ ä¼˜å…ˆçº§2: æ£€æŸ¥æ˜¯å¦åŒ¹é…æœ‰æ•ˆæŠ€æœ¯æ¨¡å¼
        for pattern in self.valid_spec_patterns:
            if re.search(pattern, combined_text, re.IGNORECASE):
                logger.debug(f"âœ… è§„æ ¼å‚æ•° '{spec_name}' åŒ¹é…æœ‰æ•ˆæŠ€æœ¯æ¨¡å¼")
                return True
        
        # ğŸš« ä¼˜å…ˆçº§3: è¿‡æ»¤æ˜æ˜¾çš„æ— æ•ˆæ¨¡å¼ - å¢å¼ºè¿‡æ»¤é€»è¾‘
        invalid_score = 0
        for category, patterns in self.invalid_spec_patterns.items():
            for pattern in patterns:
                if re.match(pattern, spec_name, re.IGNORECASE):
                    invalid_score += 1
                    logger.debug(f"ğŸ” è§„æ ¼å‚æ•° '{spec_name}' åŒ¹é…æ— æ•ˆæ¨¡å¼ {category}: {pattern}")
                    
                    # ğŸ”§ å¦‚æœå‚æ•°å€¼åŒ…å«æŠ€æœ¯ä¿¡æ¯ï¼Œç»™ä¸€æ¬¡æœºä¼š
                    if spec_value and self._contains_technical_info(spec_value):
                        logger.debug(f"âš ï¸ è§„æ ¼å‚æ•° '{spec_name}' åŒ¹é…æ— æ•ˆæ¨¡å¼ä½†å€¼åŒ…å«æŠ€æœ¯ä¿¡æ¯ï¼Œç»§ç»­è¯„ä¼°")
                        break
                    elif category in ['obvious_garbage', 'format_chars', 'table_format_noise', 'page_elements']:
                        # æ˜æ˜¾åƒåœ¾å†…å®¹ã€è¡¨æ ¼æ ¼å¼å™ªå£°ã€é¡µé¢å…ƒç´ ç›´æ¥è¿‡æ»¤
                        logger.debug(f"âŒ è§„æ ¼å‚æ•° '{spec_name}' è¢«ç›´æ¥è¿‡æ»¤ (ç±»åˆ«: {category})")
                        return False
        
        # ğŸ” æ™ºèƒ½éªŒè¯é€»è¾‘ - å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿ
        validation_score = 0
        validation_reasons = []
        
        # 1. é•¿åº¦åˆç†æ€§æ£€æŸ¥
        if 1 <= len(spec_name) <= 30:
            validation_score += 10
            validation_reasons.append("é•¿åº¦åˆç†")
        
        # 2. åŒ…å«æ•°å­—ï¼ˆæŠ€æœ¯å‚æ•°ç»å¸¸æœ‰æ•°å­—ï¼‰
        if re.search(r'\d', combined_text):
            validation_score += 15
            validation_reasons.append("åŒ…å«æ•°å­—")
        
        # 3. åŒ…å«ä¸­æ–‡æˆ–è‹±æ–‡
        has_chinese = bool(re.search(r'[\u4e00-\u9fff]', spec_name))
        has_english = bool(re.search(r'[a-zA-Z]{2,}', spec_name))
        if has_chinese or has_english:
            validation_score += 15
            validation_reasons.append("åŒ…å«æ–‡å­—")
        
        # 4. æŠ€æœ¯å•ä½æ¨¡å¼
        if re.search(r'[0-9]+\s*[a-zA-Z%Â°â„ƒÎ©kMG]+', combined_text):
            validation_score += 25
            validation_reasons.append("åŒ…å«æŠ€æœ¯å•ä½")
        
        # 5. æ¯”å€¼å’ŒèŒƒå›´æ¨¡å¼ï¼ˆç”µåŠ›è®¾å¤‡å¸¸è§ï¼‰
        if re.search(r'[0-9]+\s*[:/\-~Â±Ã—]\s*[0-9]+', combined_text):
            validation_score += 20
            validation_reasons.append("åŒ…å«æ¯”å€¼/èŒƒå›´")
        
        # 6. æŠ€æœ¯å…³é”®è¯åŠ åˆ†
        technical_keywords = [
            # ä¸­æ–‡å…³é”®è¯
            'ç”µ', 'æµ', 'å‹', 'åŠŸ', 'ç‡', 'é¢‘', 'æ¸©', 'åº¦', 'ç²¾', 'é‡', 'æµ‹', 'è¯•', 'ä¿', 'æŠ¤',
            'å˜', 'æ¯”', 'ç»„', 'åˆ«', 'è¾“', 'å‡º', 'å…¥', 'ç›¸', 'çº¿', 'è´Ÿ', 'è½½', 'é˜»', 'æŠ—',
            # è‹±æ–‡å…³é”®è¯
            'volt', 'amp', 'watt', 'freq', 'temp', 'test', 'prot', 'meas', 'spec', 'param',
            'ratio', 'phase', 'output', 'input', 'current', 'power', 'trans'
        ]
        
        for keyword in technical_keywords:
            if keyword in spec_name.lower() or keyword in spec_value.lower():
                validation_score += 20
                validation_reasons.append(f"åŒ…å«æŠ€æœ¯å…³é”®è¯: {keyword}")
                break
        
        # 7. æŠ€æœ¯ç¼©å†™åŠ åˆ†
        if re.match(r'^[A-Z]{2,5}$', spec_name):  # AC, DC, RS485ç­‰
            validation_score += 15
            validation_reasons.append("æŠ€æœ¯ç¼©å†™æ ¼å¼")
        
        # 8. å‚æ•°ç¼–å·æ ¼å¼åŠ åˆ†
        if re.match(r'^\w{1,3}\d+$', spec_name):  # V1, A2, f0ç­‰
            validation_score += 15
            validation_reasons.append("å‚æ•°ç¼–å·æ ¼å¼")
        
        # 9. å¦‚æœæœ‰å€¼ï¼Œæ£€æŸ¥å€¼çš„æŠ€æœ¯æ€§
        if spec_value:
            if re.search(r'[\d\.]+', spec_value):
                validation_score += 10
                validation_reasons.append("å€¼åŒ…å«æ•°å­—")
            if len(spec_value) >= 2:
                validation_score += 5
                validation_reasons.append("æœ‰å®é™…å€¼")
        
        # æ‰£åˆ†é¡¹ï¼šæ— æ•ˆæ¨¡å¼åŒ¹é…
        validation_score -= invalid_score * 5
        
        # å†³ç­–é˜ˆå€¼
        threshold = 30  # é™ä½é˜ˆå€¼ï¼Œå‡å°‘è¯¯æ€
        is_valid = validation_score >= threshold
        
        if is_valid:
            logger.debug(f"âœ… è§„æ ¼å‚æ•° '{spec_name}' = '{spec_value}' éªŒè¯é€šè¿‡ (å¾—åˆ†: {validation_score}, åŸå› : {', '.join(validation_reasons)})")
        else:
            logger.debug(f"âŒ è§„æ ¼å‚æ•° '{spec_name}' = '{spec_value}' éªŒè¯å¤±è´¥ (å¾—åˆ†: {validation_score}, åŸå› : {', '.join(validation_reasons)})")
        
        return is_valid
    
    def _contains_technical_info(self, value: str) -> bool:
        """æ£€æŸ¥å€¼æ˜¯å¦åŒ…å«æ˜ç¡®çš„æŠ€æœ¯ä¿¡æ¯"""
        if not value:
            return False
            
        # åŒ…å«å•ä½çš„æ•°å€¼
        if re.search(r'\d+\s*[VvAaWwHhÎ©â„ƒâ„‰%kKmMgG]', value):
            return True
        
        # åŒ…å«æ˜ç¡®çš„æŠ€æœ¯è¯æ±‡
        if re.search(r'(ç”µå‹|ç”µæµ|åŠŸç‡|é¢‘ç‡|å˜æ¯”|ç»„åˆ«|ç›¸|çº¿|voltage|current|power|frequency|ratio|phase)', value, re.IGNORECASE):
            return True
        
        # åŒ…å«èŒƒå›´å€¼
        if re.search(r'\d+\s*[-~Â±]\s*\d+', value):
            return True
        
        # åŒ…å«æ¯”å€¼
        if re.search(r'\d+\s*[:/]\s*\d+', value):
            return True
            
        return False
    
    def _clean_specification_data(self, specifications: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ¸…ç†è§„æ ¼å‚æ•°æ•°æ®ï¼Œç§»é™¤æ— æ•ˆé¡¹ç›®
        
        Args:
            specifications: åŸå§‹è§„æ ¼å‚æ•°å­—å…¸
            
        Returns:
            Dict: æ¸…ç†åçš„è§„æ ¼å‚æ•°å­—å…¸
        """
        cleaned_specs = {}
        filtered_count = 0
        
        for spec_name, spec_data in specifications.items():
            # è·å–è§„æ ¼å€¼ç”¨äºéªŒè¯
            spec_value = ""
            if isinstance(spec_data, dict):
                spec_value = spec_data.get('value', '') or spec_data.get('raw_value', '')
            elif isinstance(spec_data, str):
                spec_value = spec_data
            
            # éªŒè¯è§„æ ¼å‚æ•°
            if self._is_valid_specification(spec_name, str(spec_value)):
                cleaned_specs[spec_name] = spec_data
            else:
                filtered_count += 1
                logger.debug(f"è¿‡æ»¤æ— æ•ˆè§„æ ¼å‚æ•°: {spec_name} = {spec_value}")
        
        if filtered_count > 0:
            logger.info(f"è§„æ ¼å‚æ•°æ¸…ç†å®Œæˆï¼šä¿ç•™ {len(cleaned_specs)} é¡¹ï¼Œè¿‡æ»¤ {filtered_count} é¡¹æ— æ•ˆå‚æ•°")
        
        return cleaned_specs

    def enhance_extraction_with_tables(self, base_extraction: Dict[str, Any], 
                                     text_content: str) -> Dict[str, Any]:
        """ç”¨è¡¨æ ¼è§£æç»“æœå¢å¼ºåŸºç¡€æå–"""
        try:
            # è§£æè¡¨æ ¼
            table_results = self.parse_document_tables(text_content)
            
            # ğŸ”§ åˆå¹¶è§„æ ¼ä¿¡æ¯ - æ·»åŠ æ•°æ®æ¸…ç†
            enhanced_specs = base_extraction.get('specifications', {}).copy()
            
            # å…ˆæ¸…ç†åŸºç¡€æå–çš„è§„æ ¼æ•°æ®
            enhanced_specs = self._clean_specification_data(enhanced_specs)
            
            # æ¸…ç†è¡¨æ ¼æå–çš„è§„æ ¼æ•°æ®
            table_specs = self._clean_specification_data(table_results.get('specifications', {}))
            
            for spec_name, spec_data in table_specs.items():
                if spec_name not in enhanced_specs:
                    # è½¬æ¢æ ¼å¼ä»¥åŒ¹é…åŸºç¡€æå–æ ¼å¼
                    enhanced_specs[spec_name] = {
                        'value': spec_data.get('raw_value', ''),
                        'unit': spec_data.get('unit', ''),
                        'description': f"ä»{spec_data.get('source', 'è¡¨æ ¼')}ä¸­æå–"
                    }
                    
                    # å¦‚æœæœ‰æ•°å€¼ï¼Œæ·»åŠ æ•°å€¼ä¿¡æ¯
                    if spec_data.get('numeric_value') is not None:
                        enhanced_specs[spec_name]['numeric_value'] = spec_data['numeric_value']
                    
                    # å¦‚æœæœ‰èŒƒå›´ï¼Œæ·»åŠ èŒƒå›´ä¿¡æ¯
                    if spec_data.get('range'):
                        enhanced_specs[spec_name]['range'] = spec_data['range']
                    
                    # å¦‚æœæœ‰å®¹å·®ï¼Œæ·»åŠ å®¹å·®ä¿¡æ¯
                    if spec_data.get('tolerance'):
                        enhanced_specs[spec_name]['tolerance'] = spec_data['tolerance']
            
            # æ›´æ–°åŸºç¡€æå–ç»“æœ
            enhanced_extraction = base_extraction.copy()
            enhanced_extraction['specifications'] = enhanced_specs
            
            # æ·»åŠ è¡¨æ ¼è§£æå…ƒæ•°æ®
            enhanced_extraction['table_parsing'] = {
                'tables_found': table_results.get('tables_found', 0),
                'parsing_confidence': table_results.get('parsing_confidence', 0.0),
                'performance_params_count': len(table_results.get('performance_parameters', {}))
            }
            
            logger.info(f"Enhanced extraction with {len(enhanced_specs)} specifications from tables")
            return enhanced_extraction
            
        except Exception as e:
            logger.error(f"Table enhancement failed: {str(e)}")
            return base_extraction